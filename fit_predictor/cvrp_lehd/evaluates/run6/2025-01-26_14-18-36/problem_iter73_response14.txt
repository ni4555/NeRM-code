```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Introduce a randomness for initial exploration
    exploration_noise = torch.randn_like(distance_matrix) * 0.05

    # Calculate capacity-based heuristic
    capacity_based_heuristic = (remaining_capacity - scaled_demands.unsqueeze(1)) * (1 - remaining_capacity.unsqueeze(0))

    # Normalize capacity-based heuristic
    capacity_based_heuristic = torch.clamp(capacity_based_heuristic, min=0.0)

    # Calculate distance-based heuristic, favoring nodes closer to the depot
    distance_based_heuristic = (1.0 / (distance_matrix[:, 0] + 1e-5))

    # Combine heuristics for final evaluation
    heuristics = capacity_based_heuristic * distance_based_heuristic + exploration_noise

    # Normalize the heuristic values to ensure consistency
    max_heuristic = heuristics.max()
    min_heuristic = heuristics.min()
    heuristics = (heuristics - min_heuristic) / (max_heuristic - min_heuristic)

    # Introduce penalties for edges with demand exceeding capacity and for returning to the depot
    capacity_penalty = torch.clamp((scaled_demands > 1.0).float() * 1000.0, min=0.0)
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(n), 0] = -1

    # Apply penalties
    heuristics -= capacity_penalty * 0.5
    heuristics += depot_penalty * 0.5

    # Introduce a local preference for edges closer to the depot
    distance_preference = distance_based_heuristic - (distance_based_heuristic - distance_based_heuristic.mean()) * 0.5

    # Combine all heuristics
    heuristics = heuristics + distance_preference

    # Clamp the heuristic values to ensure a balanced distribution
    heuristics = torch.clamp(heuristics, min=0.0, max=1.0)

    return heuristics
```
