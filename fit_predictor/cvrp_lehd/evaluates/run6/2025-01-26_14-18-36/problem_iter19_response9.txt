```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Calculate the heuristics value for each edge based on scaled demand and remaining capacity
    heuristics = (scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)).abs() * remaining_capacity

    # Add a multi-scale penalty for edges that lead to a node with demand greater than vehicle capacity
    multi_scale_penalty = (scaled_demands > 1.0).float() * 1000.0
    heuristics -= multi_scale_penalty

    # Blend penalties based on the scale of the distance from the depot
    scale = (distance_matrix[:, 0] - distance_matrix[:, 0].mean()) / distance_matrix[:, 0].std()
    scale_penalty = scale * 100
    heuristics -= scale_penalty

    # Dampen the penalties to ensure adaptability in the search process
    dampened_penalty = heuristics - scale_penalty
    dampened_penalty = torch.clamp(dampened_penalty, min=-1000, max=0)

    # Normalize the heuristic values to the range [0, 1]
    max_heuristic = dampened_penalty.max()
    min_heuristic = dampened_penalty.min()
    if max_heuristic != min_heuristic:
        dampened_penalty = (dampened_penalty - min_heuristic) / (max_heuristic - min_heuristic)
    else:
        # Avoid division by zero
        dampened_penalty = torch.ones_like(dampened_penalty)

    return dampened_penalty
```
