```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Calculate heuristic value using normalized distance and remaining capacity
    heuristics = (distance_matrix * remaining_capacity).squeeze()

    # Calculate penalties for capacity exceeding and for edges leading back to the depot
    capacity_penalty = (scaled_demands > 1.0).float() * -1000.0
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(n), 0] = -1

    # Introduce penalties and preferences into heuristic values
    heuristics = heuristics - (capacity_penalty * remaining_capacity)
    heuristics += depot_penalty * 0.5

    # Introduce a preference for edges closer to the depot
    distance_from_depot = distance_matrix[:, 0]
    distance_preference = torch.clamp(distance_from_depot - distance_from_depot.mean(), min=0) * 5
    heuristics += distance_preference * 0.5

    # Apply non-linear transformation to dampen high penalties and encourage balance
    heuristics = torch.sigmoid(heuristics)

    # Clamp the heuristic values to ensure a balanced heuristic distribution
    heuristics = torch.clamp(heuristics, min=0.0, max=1.0)

    return heuristics
```
