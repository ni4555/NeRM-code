```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Initialize the heuristic matrix
    heuristics = torch.zeros_like(distance_matrix)

    # Strong penalty for capacity violations
    capacity_penalty = torch.clamp((scaled_demands > 1.0).float() * 1000.0, min=0.0)
    heuristics += capacity_penalty

    # Dampened penalty for edges leading back to the depot (index 0)
    dampening_factor = 0.5
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(n), 0] = -1
    heuristics += depot_penalty * dampening_factor

    # Penalty for edges too far from the depot (local preference)
    distance_penalty = (distance_matrix[:, 0] - distance_matrix[:, 0].mean()) * 30
    heuristics += torch.clamp(distance_penalty, min=0.0) * dampening_factor

    # Incentive for edges with remaining capacity
    exploration_incentive = (remaining_capacity / remaining_capacity.max()) * 0.1
    heuristics += exploration_incentive.unsqueeze(1) * exploration_incentive.unsqueeze(0)

    # Normalize the heuristic values to the range [0, 1] using min-max scaling
    max_heuristic = heuristics.max()
    min_heuristic = heuristics.min()
    heuristics = (heuristics - min_heuristic) / (max_heuristic - min_heuristic)

    # Non-linear transformation to avoid local optima
    heuristics = torch.tanh(heuristics)

    # Ensure heuristics are balanced by scaling to ensure they sum to 1
    balanced_heuristics = heuristics / heuristics.sum()

    # Clamp the heuristics to ensure they are within the [0, 1] range
    balanced_heuristics = torch.clamp(balanced_heuristics, min=0.0, max=1.0)

    return balanced_heuristics
```
