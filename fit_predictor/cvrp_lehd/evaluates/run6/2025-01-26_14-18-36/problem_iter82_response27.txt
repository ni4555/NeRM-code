```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    cumulative_demand = torch.cumsum(scaled_demands, dim=0)
    remaining_capacity = total_capacity - cumulative_demand

    demand_diff = (scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)).abs()
    dampened_demand_diff = torch.clamp(1.0 / (demand_diff + 1e-5), max=1.0)
    heuristics = dampened_demand_diff * remaining_capacity

    # Using smaller noise scale to improve stability
    exploration_noise = torch.randn_like(heuristics) * 0.01

    # Apply penalties directly without separate variable
    capacity_penalty = torch.clamp((scaled_demands > 1.0).float() * 1000.0, min=0.0)
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(n), 0] = -1

    # Calculate heuristic values
    heuristics = (heuristics - exploration_noise + capacity_penalty - depot_penalty)

    # Adjust preferences with domain-specific insight
    distance_preference = distance_matrix[:, 0] / distance_matrix[:, 0].max()
    heuristics += distance_preference

    # Ensure balanced heuristic distribution with normalization
    heuristics = torch.clamp(heuristics, min=0.0, max=1.0)

    return heuristics
```
