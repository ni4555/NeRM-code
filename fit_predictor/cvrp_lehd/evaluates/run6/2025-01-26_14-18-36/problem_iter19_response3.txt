```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Initialize heuristic values
    heuristics = (scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)).abs() * remaining_capacity

    # Implement balance constraint by using a weighted sum of positive and negative heuristics
    positive_part = torch.where(heuristics > 0, heuristics, 0)
    negative_part = torch.where(heuristics < 0, -heuristics, 0)
    weight_positive = 1.0
    weight_negative = 1.0
    heuristics = (weight_positive * positive_part + weight_negative * negative_part) / (weight_positive + weight_negative)

    # Introduce a multi-scale penalty to penalize large jumps in demand and large jumps in distance
    penalty = torch.abs(cumulative_demand[:, None] - cumulative_demand)
    penalty *= 100.0
    penalty[penalty > 0] += (distance_matrix[1:] - distance_matrix[:-1]) * 0.1

    # Implement dampening to adapt to new information over time, e.g., with exponential decay
    decay = 0.5
    if decay != 1.0:
        heuristics = heuristics * decay + (1.0 - decay) * (positive_part - negative_part)

    # Normalize for consistency by scaling heuristic values to the range [0, 1]
    max_heuristic = heuristics.max()
    min_heuristic = heuristics.min()
    heuristics = (heuristics - min_heuristic) / (max_heuristic - min_heuristic)

    # Combine all components of the heuristic, with a priority on feasibility
    combined = heuristics - penalty
    heuristics = torch.clamp(combined, min=-1000.0, max=1000.0)  # Apply strong bounds

    return heuristics
```
