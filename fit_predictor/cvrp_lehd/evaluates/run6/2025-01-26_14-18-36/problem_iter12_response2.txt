```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Precompute remaining capacity for all nodes
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)
    remaining_capacity = total_capacity - cumulative_demand

    # Calculate the demand difference
    demand_diff = scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)

    # Calculate the heuristic value based on the difference and remaining capacity
    heuristics = demand_diff.abs() * remaining_capacity

    # Apply penalties for edges leading to overflow in capacity and local preference for edges closer to the depot
    capacity_overflow_penalty = (scaled_demands > 1.0).float() * -1000.0
    distance_preference = (distance_matrix[:, 0] - distance_matrix[:, 0].mean()).neg() * 100
    combined_penalties = capacity_overflow_penalty + distance_preference

    # Add penalties to the heuristics
    heuristics += combined_penalties

    # Avoid sending a vehicle back to the depot unnecessarily
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(n), 0] = -1
    heuristics += depot_penalty

    # Normalize the heuristic values to the range [0, 1]
    max_heuristic = heuristics.max()
    min_heuristic = heuristics.min()
    heuristics_normalized = (heuristics - min_heuristic) / (max_heuristic - min_heuristic)

    # Avoid division by zero in normalization
    heuristics_normalized = torch.where(max_heuristic != min_heuristic, heuristics_normalized, torch.ones_like(heuristics_normalized))

    return heuristics_normalized
```
