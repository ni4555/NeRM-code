```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Calculate the heuristics value for each edge based on scaled demand and remaining capacity
    heuristics = (scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)).abs() * remaining_capacity

    # Add a penalty for edges that lead to a node with demand greater than vehicle capacity
    penalty = (scaled_demands > 1.0).float() * 1000.0
    heuristics -= penalty

    # Add a small penalty for edges leading back to the depot (index 0)
    penalty = torch.zeros_like(distance_matrix)
    penalty[torch.arange(distance_matrix.shape[0]), 0] = -1
    heuristics += penalty

    # Introduce a preference for edges that are closer to the depot
    distance_preference = -distance_matrix[:, 0]

    # Combine the heuristic values with the penalties and preferences, ensuring that the penalties dominate for infeasible edges
    combined_values = heuristics + distance_preference
    combined_penalties = torch.max(penalty, distance_preference)
    combined_values = torch.where(combined_penalties > 0, combined_penalties, combined_values)

    # Normalize the heuristic values to the range [0, 1]
    max_value = combined_values.max()
    min_value = combined_values.min()
    if max_value != min_value:
        combined_values = (combined_values - min_value) / (max_value - min_value)
    else:
        # Avoid division by zero
        combined_values = torch.ones_like(combined_values)

    return combined_values
```
