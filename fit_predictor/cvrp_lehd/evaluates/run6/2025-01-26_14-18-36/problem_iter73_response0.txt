```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:

    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Normalize demand differences to encourage diversity
    demand_diff = (scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)).abs()

    # Calculate heuristic value using normalized demand differences and remaining capacity
    heuristics = demand_diff * remaining_capacity

    # Introduce randomness for exploration, dampened to prevent high penalties
    exploration_noise = torch.randn_like(heuristics) * 0.01
    heuristics += exploration_noise

    # Normalize heuristic values for exploration
    heuristics = (heuristics - heuristics.min()) / (heuristics.max() - heuristics.min())

    # Dampen high penalties to balance exploration and exploitation
    heuristics = torch.log1p(heuristics)

    # Introduce penalties for capacity exceeding nodes and edges back to the depot
    capacity_penalty = (scaled_demands > 1.0).float() * 1000.0
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(n), 0] = -1
    heuristics -= (capacity_penalty + depot_penalty) * 0.5

    # Encourage local preference for edges closer to the depot
    distance_penalty = (distance_matrix[:, 0] - distance_matrix[:, 0].mean()) * 10
    distance_penalty = torch.log1p(torch.relu(distance_penalty))
    heuristics -= distance_penalty * 0.5

    # Clamp the heuristic values to a balanced range
    heuristics = torch.clamp(heuristics, min=0.0, max=1.0)

    return heuristics
```
