1. Blend penalties with exploration; adapt based on constraint violations.
2. Normalize early for diversity, transform later for balance.
3. Dampen high penalties, use non-linear transformations to navigate.
4. Incorporate randomness, balance exploration & exploitation.
5. Optimize diversity, avoid dominance, and simplify calculations.
