```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:

    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    scaled_demands = demands / total_capacity

    # Calculate cumulative demand from the depot to each node
    cumulative_demand = torch.cumsum(scaled_demands, dim=0)

    # Calculate remaining capacity at each node
    remaining_capacity = total_capacity - cumulative_demand

    # Calculate the heuristic value for each edge based on scaled demand and remaining capacity
    heuristics = (scaled_demands.unsqueeze(1) - scaled_demands.unsqueeze(0)).abs() * remaining_capacity

    # Add a dampening effect to prevent overly optimistic heuristics
    dampening_factor = 0.5
    heuristics *= dampening_factor

    # Apply a penalty for edges that lead to a node with demand greater than vehicle capacity
    capacity_penalty = torch.clamp((scaled_demands > 1.0).float() * 1000.0, min=0.0)
    heuristics -= capacity_penalty

    # Introduce a balance factor to penalize both high and low capacity utilization
    balance_factor = 0.2
    balance_term = balance_factor * (1 - torch.tanh(remaining_capacity))
    heuristics -= balance_term

    # Introduce a normalization term to ensure all heuristics are positive
    normalization_term = torch.min(heuristics) + 1
    heuristics /= normalization_term

    # Add a penalty for edges leading back to the depot (index 0)
    depot_penalty = torch.zeros_like(distance_matrix)
    depot_penalty[torch.arange(distance_matrix.shape[0]), 0] = -1
    heuristics += depot_penalty

    # Introduce a preference for edges close to the depot (local preference)
    distance_preference = (distance_matrix[:, 0] - distance_matrix[:, 0].mean())
    heuristics += distance_preference * 0.1

    return heuristics
```
