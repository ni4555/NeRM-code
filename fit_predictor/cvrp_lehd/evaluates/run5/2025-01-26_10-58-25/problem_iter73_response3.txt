```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Introduce randomness by adding Gaussian noise with a small standard deviation
    noise_matrix = torch.randn_like(potential_matrix) * 1e-2
    
    # Combine the original potential matrix with noise
    combined_potential_matrix = potential_matrix + noise_matrix
    
    # Apply a non-linear transformation to emphasize constraints
    emphasized_matrix = torch.exp(-torch.abs(combined_potential_matrix))
    
    # Normalize the emphasized matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = emphasized_matrix / emphasized_matrix.sum(dim=1, keepdim=True)
    
    # Combine the normalized emphasized matrix with the distance penalty matrix
    combined_matrix = normalized_emphasized_matrix + 0.5 * distance_penalty_matrix
    
    # Introduce a second noise term for further randomness
    second_noise_matrix = torch.randn_like(combined_matrix) * 1e-2
    
    # Adjust the combined matrix to account for additional randomness
    adjusted_combined_matrix = combined_matrix + second_noise_matrix
    
    # Introduce diversity by shuffling the matrix to avoid local optima
    shuffled_matrix = adjusted_combined_matrix.clone()
    for i in range(shuffled_matrix.size(0)):
        shuffled_matrix[i] = shuffled_matrix[i].numpy()
        shuffled_matrix[i] = shuffled_matrix[i][shuffled_matrix[i].argsort()]
        shuffled_matrix[i] = shuffled_matrix[i].astype(torch.float32)
    
    # Apply a final non-linear transformation to ensure a balance between randomness and structure
    final_emphasized_matrix = torch.exp(-torch.abs(shuffled_matrix))
    
    # Normalize the final emphasized matrix to ensure non-negativity and scale balance
    final_normalized_emphasized_matrix = final_emphasized_matrix / final_emphasized_matrix.sum(dim=1, keepdim=True)
    
    # Transform the final normalized emphasized matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -final_normalized_emphasized_matrix
    
    return heuristics_matrix
```
