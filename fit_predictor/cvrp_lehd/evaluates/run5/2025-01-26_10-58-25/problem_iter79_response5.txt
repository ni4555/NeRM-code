```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:

    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Introduce randomness by adding Gaussian noise with a smaller standard deviation
    noise_matrix = torch.randn_like(penalty_matrix) * 1e-3
    
    # Apply a non-linear transformation to emphasize constraints with randomness
    emphasized_matrix = torch.exp(-torch.abs(penalty_matrix + noise_matrix))
    
    # Normalize the emphasized matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = emphasized_matrix / emphasized_matrix.sum(dim=1, keepdim=True)
    
    # Combine the normalized emphasized matrix with a distance-based penalty matrix
    combined_matrix = normalized_emphasized_matrix + torch.log(distance_matrix + 1e-6)
    
    # Introduce a second noise term for further randomness, balanced by the distance penalty
    second_noise_matrix = torch.randn_like(combined_matrix) * 1e-2
    combined_matrix = combined_matrix + second_noise_matrix
    
    # Control randomness by limiting the effect of the second noise term
    limited_noise_matrix = torch.clamp(combined_matrix, min=-1, max=1)
    
    # Apply a mutation step by adding a small random perturbation to the matrix
    mutation_factor = torch.rand_like(limited_noise_matrix)
    mutated_combined_matrix = limited_noise_matrix + torch.randn_like(limited_noise_matrix) * 1e-3 * mutation_factor
    
    # Final transformation into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -mutated_combined_matrix
    
    return heuristics_matrix
```
