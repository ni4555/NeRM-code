```python
import torch

def softmax(x, dim):
    exp_x = torch.exp(x - torch.max(x, dim=dim)[0])
    return exp_x / exp_x.sum(dim=dim, keepdim=True)

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)  # Adding a small constant to avoid log(0)
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Emphasize the constraints by using a non-linear transform (sigmoid)
    emphasized_matrix = 1 / (1 + torch.exp(-potential_matrix))
    
    # Normalize the combined matrix to ensure that the values are not too close to zero
    normalized_combined_matrix = emphasized_matrix / emphasized_matrix.sum(dim=1, keepdim=True)
    
    # Ensure that the normalized matrix has positive values for further processing
    positive_normalized_combined_matrix = normalized_combined_matrix + torch.min(normalized_combined_matrix)
    
    # Transform the positive_normalized_combined_matrix to a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -positive_normalized_combined_matrix
    
    return heuristics_matrix
```
