```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Introduce randomness by adding Gaussian noise with a small standard deviation
    noise_matrix = torch.randn_like(potential_matrix) * 1e-2
    
    # Combine the original potential matrix with noise
    combined_potential_matrix = potential_matrix + noise_matrix
    
    # Apply a non-linear transformation to emphasize constraints
    emphasized_matrix = torch.exp(-torch.abs(combined_potential_matrix))
    
    # Normalize the emphasized matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = emphasized_matrix / emphasized_matrix.sum(dim=1, keepdim=True)
    
    # Introduce diversity by ensuring a minimum threshold for the potential values
    diversity_threshold = torch.min(normalized_emphasized_matrix)
    normalized_emphasized_matrix = torch.where(normalized_emphasized_matrix < diversity_threshold,
                                              normalized_emphasized_matrix + diversity_threshold,
                                              normalized_emphasized_matrix)
    
    # Limit noise to avoid overly random solutions
    limited_noise_matrix = noise_matrix * torch.clamp(1 - normalized_emphasized_matrix.sum(dim=1, keepdim=True), min=0)
    
    # Combine the normalized emphasized matrix with the limited noise
    combined_matrix = normalized_emphasized_matrix + limited_noise_matrix
    
    # Introduce a second noise term for further randomness
    second_noise_matrix = torch.randn_like(combined_matrix) * 1e-2
    
    # Adjust the combined matrix to account for additional randomness
    adjusted_combined_matrix = combined_matrix + second_noise_matrix
    
    # Introduce a third noise term to introduce even more randomness
    third_noise_matrix = torch.randn_like(adjusted_combined_matrix) * 1e-2
    
    # Adjust the adjusted combined matrix to account for additional randomness
    final_combined_matrix = adjusted_combined_matrix + third_noise_matrix
    
    # Ensure that the sum of heuristics is non-negative to avoid negative cost assignments
    final_combined_matrix = final_combined_matrix - final_combined_matrix.min()
    
    # Transform the final combined matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -final_combined_matrix
    
    return heuristics_matrix
```
