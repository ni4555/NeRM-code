```python
import torch

def softmax(tensor: torch.Tensor, dim: int) -> torch.Tensor:
    e_tensor = torch.exp(tensor - tensor.max(dim=dim, keepdim=True)[0])
    return e_tensor / e_tensor.sum(dim=dim, keepdim=True)

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Normalize the potential matrix to ensure non-negativity and scale balance
    normalized_potential_matrix = softmax(potential_matrix, dim=1)
    
    # Apply a penalty to the edges leading back to the depot to discourage them
    depot_penalty_matrix = -torch.ones_like(distance_matrix) * 1000
    adjusted_normalized_matrix = torch.min(normalized_potential_matrix, depot_penalty_matrix)
    
    # The adjusted_normalized_matrix already represents a non-negative heuristic value,
    # with larger values corresponding to more promising edges. Therefore, we can return it
    # directly without the need for additional scaling.
    
    return adjusted_normalized_matrix
```
