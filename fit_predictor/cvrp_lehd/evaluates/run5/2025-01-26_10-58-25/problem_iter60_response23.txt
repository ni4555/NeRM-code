```python
import torch

def softmax(tensor, dim):
    exp_tensor = torch.exp(tensor - torch.max(tensor, dim=dim, keepdim=True)[0])
    sum_exp_tensor = torch.sum(exp_tensor, dim=dim, keepdim=True)
    return exp_tensor / sum_exp_tensor

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Normalize the potential matrix to ensure non-negativity and scale balance
    normalized_potential_matrix = softmax(potential_matrix, dim=1)
    
    # Introduce a diversity and stability factor to encourage a wide range of edge choices
    diversity_factor = torch.mean(normalized_potential_matrix, dim=1, keepdim=True)
    stability_factor = torch.std(normalized_potential_matrix, dim=1, keepdim=True)
    normalized_potential_matrix -= diversity_factor
    normalized_potential_matrix /= stability_factor
    
    # Ensure that the values are not too close to zero
    normalized_potential_matrix = torch.clamp(normalized_potential_matrix, min=1e-6)
    
    # Introduce a balancing factor to ensure that both penalties contribute equally
    balancing_factor = torch.max(normalized_potential_matrix) / normalized_potential_matrix
    balanced_combined_matrix = normalized_potential_matrix / balancing_factor
    
    # Transform the balanced combined matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -balanced_combined_matrix
    
    return heuristics_matrix
```
