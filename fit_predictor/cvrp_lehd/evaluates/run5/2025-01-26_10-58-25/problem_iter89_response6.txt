```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    demand_penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Use a demand-based initial potential that emphasizes closer nodes for higher demand
    potential_matrix = demand_penalty_matrix - torch.log(distance_matrix + 1e-6)
    
    # Introduce randomness early to explore diverse solutions
    random_matrix = torch.randn_like(potential_matrix) * 1e-2
    
    # Combine initial potential with randomness
    combined_potential_matrix = potential_matrix + random_matrix
    
    # Normalize combined potential matrix to ensure all values are non-negative
    normalized_combined_potential_matrix = torch.relu(combined_potential_matrix)
    
    # Balance demand and distance penalties by combining with a normalized distance penalty matrix
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)
    normalized_distance_penalty_matrix = distance_penalty_matrix / distance_penalty_matrix.sum(dim=1, keepdim=True)
    
    # Combine normalized potentials with distance penalties
    balanced_potential_matrix = normalized_combined_potential_matrix + normalized_distance_penalty_matrix
    
    # Introduce non-linear transformation to emphasize constraints and balance the matrix
    emphasized_matrix = torch.log1p(balanced_potential_matrix)
    
    # Mutation: apply a small random perturbation to the matrix
    mutation_factor = torch.rand_like(emphasized_matrix)
    mutated_emphasized_matrix = emphasized_matrix + torch.randn_like(emphasized_matrix) * 1e-3 * mutation_factor
    
    # Final transformation to heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -mutated_emphasized_matrix
    
    return heuristics_matrix
```
