```python
import torch
import torch.nn.functional as F

def softmax(x, dim):
    e_x = torch.exp(x - torch.max(x, dim=dim, keepdim=True)[0])
    return e_x / e_x.sum(dim=dim, keepdim=True)

def normalize(x, p=1, dim):
    if p == 1:
        return x / x.norm(dim=dim, p=p)
    else:
        return x / x.pow(p).sum(dim=dim, p=p).pow(1/p)

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Normalize the distance matrix early to balance constraints
    normalized_distance_matrix = softmax(-torch.log(distance_matrix + 1e-6), dim=1)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -normalized_distance_matrix
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Apply a non-linear transformation to emphasize constraints
    emphasized_matrix = torch.exp(-torch.abs(potential_matrix))
    
    # Normalize the emphasized matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = normalize(emphasized_matrix, p=1, dim=1)
    
    # Blend penalties to enhance heuristic diversity and stability
    blend_ratio = 0.9  # Optimized blend ratio for performance
    blended_penalty = blend_ratio * normalized_emphasized_matrix + (1 - blend_ratio) * distance_penalty_matrix
    
    # Adjust the blended penalty matrix to ensure that the values are not too close to zero
    adjusted_blended_penalty = blended_penalty - torch.min(blended_penalty)
    
    # Transform the adjusted blended penalty matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -adjusted_blended_penalty
    
    return heuristics_matrix
```
