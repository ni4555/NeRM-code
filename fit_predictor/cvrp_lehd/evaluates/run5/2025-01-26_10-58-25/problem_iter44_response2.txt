```python
import torch
from torch.nn.functional import softmax

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)  # Adding a small constant to avoid log(0)
    
    # Normalize the distance penalty matrix to the same scale as the penalty matrix
    distance_penalty_matrix /= vehicle_capacity
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = penalty_matrix + distance_penalty_matrix
    
    # Apply a non-linear transformation to emphasize constraints
    emphasized_matrix = torch.relu(potential_matrix)
    
    # Normalize the emphasized matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = softmax(emphasized_matrix / emphasized_matrix.sum(dim=1, keepdim=True), dim=1)
    
    # Balance the demand and distance penalties using a linear combination
    combined_matrix = 0.2 * normalized_emphasized_matrix + 0.8 * distance_penalty_matrix
    
    # Adjust the combined matrix to ensure the values are not too close to zero
    adjusted_combined_matrix = combined_matrix - torch.min(combined_matrix)
    
    # Normalize the combined matrix to ensure it is not dominating the distance penalties
    log_sum_exp = torch.log(adjusted_combined_matrix.exp().sum(dim=1, keepdim=True))
    normalized_combined_matrix = adjusted_combined_matrix - log_sum_exp
    
    # Transform the normalized combined matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -normalized_combined_matrix
    
    return heuristics_matrix
```
