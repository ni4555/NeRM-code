```python
import torch
import torch.nn.functional as F

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:

    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Normalize the distance matrix
    normalized_distance_matrix = distance_matrix / distance_matrix.max()
    
    # Create a combined penalty matrix that emphasizes both demand and distance
    combined_penalty_matrix = (1 - 0.6) * penalty_matrix + 0.6 * normalized_distance_matrix
    
    # Apply a selective scaling based on demand violations
    demand_scale_matrix = torch.exp(-torch.abs(penalty_matrix))
    
    # Normalize the demand scale matrix
    normalized_demand_scale_matrix = F.softmax(demand_scale_matrix, dim=1)
    
    # Combine the scaled demand penalties with the normalized distance matrix
    combined_potential_matrix = normalized_demand_scale_matrix * combined_penalty_matrix
    
    # Apply a non-linear transformation to emphasize constraints
    emphasized_potential_matrix = torch.pow(combined_potential_matrix, 1.5)
    
    # Normalize the emphasized potential matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = F.softmax(emphasized_potential_matrix, dim=1)
    
    # Scale down the normalized emphasized matrix to prevent overflow
    scaled_normalized_emphasized_matrix = normalized_emphasized_matrix * (1 / normalized_emphasized_matrix.max())
    
    # Transform the scaled normalized matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -scaled_normalized_emphasized_matrix
    
    return heuristics_matrix
```
