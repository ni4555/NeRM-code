```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:

    vehicle_capacity = demands.sum() / demands.numel()
    
    # Introduce randomness from the start by adding Gaussian noise
    noise_matrix = torch.randn_like(distance_matrix) * 1e-2
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Combine noise and demand penalties into a single potential matrix
    potential_matrix = noise_matrix + penalty_matrix
    
    # Normalize the potential matrix to ensure non-negativity and scale balance
    normalized_potential_matrix = potential_matrix / (potential_matrix.sum(dim=1, keepdim=True) + 1e-6)
    
    # Use a distance-based potential matrix to emphasize short distances
    distance_potential_matrix = -torch.log(distance_matrix + 1e-6)
    
    # Combine both potentials to get a weighted potential matrix
    combined_potential_matrix = (normalized_potential_matrix + distance_potential_matrix) / 2
    
    # Apply a non-linear transformation to emphasize constraints
    emphasized_matrix = torch.exp(-torch.abs(combined_potential_matrix))
    
    # Introduce controlled randomness by adding a small random perturbation
    controlled_noise_matrix = torch.randn_like(emphasized_matrix) * 1e-2
    
    # Adjust the emphasized matrix to account for controlled randomness
    adjusted_emphasized_matrix = emphasized_matrix + controlled_noise_matrix
    
    # Introduce mutation by adding a small random perturbation with a controlled factor
    mutation_factor = torch.rand_like(adjusted_emphasized_matrix)
    mutated_emphasized_matrix = adjusted_emphasized_matrix + torch.randn_like(adjusted_emphasized_matrix) * 1e-3 * mutation_factor
    
    # Final transformation into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -mutated_emphasized_matrix
    
    return heuristics_matrix
```
