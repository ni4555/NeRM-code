```python
import torch
import torch.nn.functional as F

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    vehicle_capacity = demands.sum() / demands.numel()
    
    # Create a penalty matrix for demand constraint violations
    penalty_matrix = -torch.abs(demands - vehicle_capacity)
    
    # Create a distance-based penalty matrix to balance demand and distance penalties
    distance_penalty_matrix = -torch.log(distance_matrix + 1e-6)  # Adding a small constant to avoid log(0)
    
    # Introduce blending factors for demand and distance penalties
    demand_blending_factor = 0.4
    distance_blending_factor = 0.6
    
    # Combine demand and distance penalties into a single potential matrix
    potential_matrix = demand_blending_factor * penalty_matrix + (1 - demand_blending_factor) * distance_penalty_matrix
    
    # Introduce a dynamic factor for diversity and stability
    dynamic_factor = torch.exp(-torch.sum(potential_matrix, dim=1) / torch.max(torch.sum(potential_matrix, dim=1)))
    
    # Apply the dynamic factor to the potential matrix
    emphasized_matrix = dynamic_factor * potential_matrix
    
    # Normalize the emphasized matrix to ensure non-negativity and scale balance
    normalized_emphasized_matrix = F.softmax(emphasized_matrix, dim=1)
    
    # Combine the normalized emphasized matrix with the distance penalty matrix using a weighted sum
    combined_matrix = distance_blending_factor * normalized_emphasized_matrix + (1 - distance_blending_factor) * distance_penalty_matrix
    
    # Adjust the combined matrix to ensure that the values are not too close to zero
    adjusted_combined_matrix = combined_matrix - torch.min(combined_matrix)
    
    # Transform the adjusted combined matrix into a heuristics matrix
    # Negative values represent undesirable edges, positive values represent promising ones
    heuristics_matrix = -adjusted_combined_matrix
    
    return heuristics_matrix
```
