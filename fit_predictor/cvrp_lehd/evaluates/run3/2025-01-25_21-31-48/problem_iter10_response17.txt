```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    # Calculate the inverse of the distance matrix to emphasize shorter distances
    distance_matrix_inv = 1 / (distance_matrix + 1e-10)  # Add a small value to avoid division by zero
    
    # Weight the inverse distance by the demand to emphasize nodes with higher demand
    demand_weighted_distance_matrix = distance_matrix_inv * demands
    
    # Introduce a penalty for uniformity by ensuring that no node is too close to the depot
    uniformity_penalty = (torch.min(distance_matrix, dim=1).values + 1e-10) / (torch.max(distance_matrix, dim=1).values + 1e-10)
    demand_weighted_distance_matrix *= uniformity_penalty
    
    # Normalize the matrix to ensure all values are within a certain range
    max_demand_weighted_distance = demand_weighted_distance_matrix.max()
    min_demand_weighted_distance = demand_weighted_distance_matrix.min()
    normalized_demand_weighted_distance_matrix = (demand_weighted_distance_matrix - min_demand_weighted_distance) / (max_demand_weighted_distance - min_demand_weighted_distance)
    
    # Introduce a penalty for uniformity by ensuring that no node is too close to the depot
    uniformity_penalty = (torch.min(distance_matrix, dim=0).values + 1e-10) / (torch.max(distance_matrix, dim=0).values + 1e-10)
    heuristics = normalized_demand_weighted_distance_matrix * uniformity_penalty
    
    # Ensure that the depot is the last node considered
    depot_penalty = torch.ones_like(heuristics)
    depot_penalty[0] = 0
    heuristics *= depot_penalty
    
    # Apply a soft penalty to edges leading to the depot when full
    for i in range(n):
        for j in range(n):
            if j == 0:  # If the edge leads to the depot
                heuristics[i, j] = heuristics[i, j] * (1 - demands[i])
    
    return heuristics
```
