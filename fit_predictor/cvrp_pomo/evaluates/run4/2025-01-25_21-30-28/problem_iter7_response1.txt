```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:

    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    normalized_demands = demands / total_capacity

    # Inverse distance heuristic: edges with shorter distances are more promising
    inverse_distance = 1.0 / (distance_matrix + 1e-8)

    # Demand normalization heuristic: edges with normalized demand closer to 1 are more promising
    demand_diff = torch.abs(normalized_demands - 1.0)
    demand_weight = 1.0 / (demand_diff + 1e-8)

    # Heuristic range adjustment: penalize edges with larger distances
    mean_distance = distance_matrix.mean()
    heuristic_range = 1.0 / (distance_matrix + mean_distance + 1e-8)

    # Load balancing strategy: prioritize edges with demand close to capacity
    load_balance = 1.0 / (1 + torch.abs(torch.linspace(0, total_capacity, steps=n) - normalized_demands))

    # Normalize and combine heuristics
    normalized_heuristics = (inverse_distance + demand_weight + heuristic_range + load_balance) / 4.0

    # Dynamically adjust the search space based on the performance of previously evaluated solutions
    search_space_adjustment = (normalized_heuristics - normalized_heuristics.mean()) * 10.0

    # Introduce a learning factor to adapt heuristics based on performance
    learning_factor = 0.99
    normalized_heuristics *= learning_factor

    # Introduce domain insights and prioritize constraints
    normalized_heuristics += search_space_adjustment

    # Clamp values to a reasonable range to avoid extreme values
    normalized_heuristics = torch.clamp(normalized_heuristics, min=-10.0, max=10.0)

    # Introduce mutation for diversification, ensuring a balance between global and local search
    mutation_factor = torch.rand_like(normalized_heuristics)
    mutated_heuristics = normalized_heuristics + mutation_factor * 1.0

    # Mutation: Introduce a penalty for large deviations from the mean
    penalty_factor = torch.clamp(torch.abs(mutated_heuristics - normalized_heuristics) * 5.0, max=10.0)
    mutated_heuristics -= penalty_factor

    # Mutation: Introduce a bonus for small deviations from the mean if they lead to improvement
    improvement_bonus = torch.clamp(torch.abs(mutated_heuristics - normalized_heuristics) * 0.5, max=10.0)
    mutated_heuristics += improvement_bonus

    # Clamp mutated values to a reasonable range to avoid extreme values
    mutated_heuristics = torch.clamp(mutated_heuristics, min=-10.0, max=10.0)

    return mutated_heuristics
```
