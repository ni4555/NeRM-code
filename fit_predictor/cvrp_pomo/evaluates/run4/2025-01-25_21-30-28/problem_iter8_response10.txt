```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    normalized_demands = demands / total_capacity

    # Inverse distance heuristic
    inverse_distance = 1.0 / (distance_matrix + 1e-8)

    # Demand normalization heuristic
    demand_diff = torch.abs(normalized_demands - 1.0)
    demand_weight = 1.0 / (demand_diff + 1e-8)

    # Heuristic range adjustment using mean distance
    mean_distance = distance_matrix.mean()
    heuristic_range = 1.0 / (distance_matrix + mean_distance + 1e-8)

    # Load balancing strategy
    load_balance = 1.0 / (1 + torch.abs(torch.linspace(0, total_capacity, steps=n) - normalized_demands))

    # Placeholder for actual performance data, this would be replaced with real data in practice
    performance_data = torch.ones(n) / n  # Equal weighting for simplicity
    performance_data = performance_data / performance_data.sum()  # Normalize performance data
    dynamic_weight = performance_data / (performance_data + 1e-8)  # Avoid division by zero

    # Dynamic weighting based on domain knowledge
    # For example, more weight might be given to edges that contribute to load balancing
    dynamic_weight *= load_balance

    # Combine heuristics with dynamic weighting
    combined_heuristic = (
        inverse_distance * 0.5 +
        demand_weight * 0.3 +
        heuristic_range * 0.2 +
        load_balance * 0.4
    ) * dynamic_weight

    # Normalize the combined heuristic to have a range of [0, 1]
    max_heuristic = combined_heuristic.max()
    min_heuristic = combined_heuristic.min()
    normalized_combined_heuristic = (combined_heuristic - min_heuristic) / (max_heuristic - min_heuristic)

    # Clamp values to a reasonable range to avoid extreme values
    normalized_combined_heuristic = torch.clamp(normalized_combined_heuristic, min=-1.0, max=1.0)

    return normalized_combined_heuristic
```
