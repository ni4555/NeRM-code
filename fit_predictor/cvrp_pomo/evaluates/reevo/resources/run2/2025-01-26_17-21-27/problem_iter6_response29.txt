```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_demand = demands.sum()
    vehicle_capacity = demands.max()
    
    # Calculate the savings for each edge
    savings = (distance_matrix**2 - torch.clamp(distance_matrix, min=1e-8)) * (demands[:, None] - demands[None, :])
    
    # Calculate the cumulative demand at each node if visited
    cumulative_demand = torch.cumsum(demands, dim=0)
    
    # Create a mask to check if adding a node exceeds the vehicle capacity
    demand_mask = cumulative_demand <= vehicle_capacity
    
    # Adjust the savings heuristic to consider demand and mask undesirable edges
    adjusted_savings = savings * demand_mask
    
    # Subtract savings for edges that exceed the vehicle capacity to promote return trips
    return_penalty = -vehicle_capacity
    adjusted_savings -= return_penalty * torch.triu(torch.ones((n, n), dtype=torch.bool), diagonal=1)
    
    # Normalize savings to ensure positive values and prevent dominance of larger edges
    min_savings = adjusted_savings.min()
    adjusted_savings -= min_savings
    
    # Add a penalty for self-loops
    self_loop_penalty = -adjusted_savings.max()
    adjusted_savings -= self_loop_penalty * torch.eye(n, dtype=torch.bool)
    
    # Additional heuristic: Promote edges closer to the diagonal (further from the depot)
    distance_to_diagonal = torch.abs(torch.arange(n)[:, None] - torch.arange(n)[None, :])
    diagonal_promotion = torch.clamp(1 - distance_to_diagonal / n, min=0)
    
    # Combine the adjusted savings with the diagonal promotion
    heuristic_matrix = adjusted_savings + diagonal_promotion
    
    return heuristic_matrix
```
