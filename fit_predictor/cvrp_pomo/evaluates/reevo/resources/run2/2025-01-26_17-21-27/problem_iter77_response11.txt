```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    cumulative_demand = torch.cumsum(demands, dim=0)
    
    # Modular design: separate penalty and heuristic calculations
    def calculate_penalty(distance, cumulative_demand, total_capacity, time_factor, scaling_factor):
        dynamic_capacity_penalty = -torch.log1p(torch.abs(demands - total_capacity) - 1e-8)
        overflow_penalty = torch.where(
            (cumulative_demand[:, None] + demands[None, :]) > total_capacity,
            -torch.log1p((cumulative_demand[:, None] + demands[None, :]) - total_capacity - 1e-8),
            torch.zeros_like(cumulative_demand)
        )
        load_balance_penalty = -torch.log1p(torch.abs(cumulative_demand - (total_capacity / n)) - 1e-8)
        return scaling_factor * (distance * time_factor + dynamic_capacity_penalty + overflow_penalty + load_balance_penalty)

    # Enhanced distance scaling
    time_factor = torch.exp(-cumulative_demand / (total_capacity * 5))
    
    # Heuristics with penalties and random diversity
    heuristics = calculate_penalty(distance_matrix, cumulative_demand, total_capacity, time_factor, scaling_factor=1.5)
    randomness_factor = torch.abs(torch.randn_like(demands)) * 0.1
    randomness_factor *= (1 - cumulative_demand / total_capacity)
    heuristics += randomness_factor
    
    # Early return mechanism to handle overflows
    early_return = cumulative_demand[:, None] > (total_capacity * 0.7)
    heuristics *= (1 + early_return)
    
    # Encourage diversity to avoid local optima
    diversity_factor = torch.abs(torch.randn_like(demands)) * 0.2
    diversity_factor /= (torch.sum(torch.abs(diversity_factor)) + 1e-8)
    diversity_factor *= (1 - cumulative_demand / total_capacity)
    heuristics += diversity_factor
    
    return heuristics
```
