```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    cumulative_demand = torch.cumsum(demands, dim=0)

    # Dynamic distance penalty to account for cumulative load
    distance_penalty = -torch.log1p(torch.abs(distance_matrix) - 1e-8)
    distance_scaling = distance_penalty * (1 + cumulative_demand / total_capacity)

    # Dynamic capacity penalty with consideration for the current load
    load_penalty = 0.1
    capacity_penalty = -torch.log1p(torch.abs(demands - total_capacity) - 1e-8)
    capacity_penalty *= load_penalty

    # Overflow penalty with early return to avoid unnecessary overflow
    overflow_penalty = torch.where(
        (cumulative_demand[:, None] + demands[None, :]) > total_capacity,
        -torch.log1p((cumulative_demand[:, None] + demands[None, :]) - total_capacity - 1e-8),
        torch.zeros_like(cumulative_demand)
    )

    # Load balance heuristic to encourage uniform load distribution
    load_balance = torch.abs(cumulative_demand - total_capacity / n)
    load_balance_penalty = -torch.log1p(load_balance - 1e-8)

    # High load balance penalty to prevent overloading
    high_load_balance_penalty = torch.where(
        load_balance > total_capacity / (2 * n) + (total_capacity / (4 * n) * torch.abs(demands - total_capacity)),
        -torch.log1p(load_balance - 1e-8),
        torch.zeros_like(load_balance)
    )

    # Combine penalties into a single heuristic score with a balanced scale factor
    scaling_factors = [1.5, 0.5, 1.0, 0.5, 0.2]  # Different scale factors for different penalties
    heuristics = sum(
        scale * penalty for scale, penalty in zip(scaling_factors, [distance_scaling, capacity_penalty, overflow_penalty, load_balance_penalty, high_load_balance_penalty])
    )

    # Add noise to encourage diversity and improve exploration
    noise = torch.rand_like(heuristics) * 0.1 - 0.05
    heuristics += noise

    return heuristics
```
