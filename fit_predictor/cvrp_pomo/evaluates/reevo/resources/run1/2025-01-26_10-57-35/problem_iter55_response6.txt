```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    
    # Incorporate demand into distance matrix
    demand_matrix = (distance_matrix * demands[:, None]). squeeze(-1)
    
    # Apply decay to edges leading to the depot to prevent domination
    depot_decay = torch.log1p(torch.abs(distance_matrix[:, 0]))
    demand_matrix[:, 0] *= depot_decay
    demand_matrix[0, :] *= depot_decay
    
    # Normalize the demand matrix to prevent any single node from dominating
    max_demand = demand_matrix.max()
    demand_matrix /= max_demand
    
    # Integrate capacity constraint by adjusting the demand matrix
    capacity_factor = (1 / (demands + 1e-8))
    demand_matrix *= capacity_factor
    
    # Avoid loops by ensuring no self-loop gets a positive heuristic value
    demand_matrix -= torch.diag(demand_matrix)
    
    # Apply penalties to promote feasibility
    overcapacity_penalty = (demands > 1).float() * -10
    undercapacity_penalty = (demands < 1).float() * 5
    demand_matrix += overcapacity_penalty - undercapacity_penalty
    
    # Normalize the entire demand matrix to prevent dominance
    normalized_demand_matrix = demand_matrix / demand_matrix.sum(dim=1, keepdim=True)
    
    # Minimize loops by setting the heuristic value of a loop to 0
    loop_heuristics = normalized_demand_matrix + normalized_demand_matrix.T - torch.diag(normalized_demand_matrix)
    loop_heuristics[loop_heuristics > 0] = 0
    
    # Apply a final decay to the normalized matrix to balance between demand and distance
    final_decay = torch.log1p(torch.abs(distance_matrix[:, 0]))
    normalized_demand_matrix *= final_decay
    
    # Add loop heuristics to the final decayed demand matrix
    heuristics = normalized_demand_matrix + loop_heuristics
    
    return heuristics
```
