```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    cumulative_demand = torch.cumsum(demands, dim=0)
    
    # Initialize heuristics matrix with zeros
    heuristics = torch.zeros_like(distance_matrix)
    
    # Iterate over all possible paths
    for i in range(1, n):  # Skip the depot node
        for j in range(i + 1, n):  # Skip the same node and the depot node
            # Calculate the potential new cumulative demand
            new_cumulative_demand = cumulative_demand[j] + demands[i]
            
            # Check if the path is feasible and not causing overflow
            if new_cumulative_demand <= total_capacity:
                # Calculate the heuristic based on the path's attributes
                distance = distance_matrix[i, j]
                load_balance = torch.abs(cumulative_demand[j] - (total_capacity - demands[i]))
                
                # Use the potential overflow and imbalance to scale the heuristic
                overflow_penalty = (new_cumulative_demand - total_capacity - 1e-8) if new_cumulative_demand > total_capacity else 0
                imbalance_penalty = -torch.log1p(load_balance - 1e-8)
                
                # Assign the heuristic value to the edge
                heuristics[i, j] = heuristics[j, i] = distance - overflow_penalty - imbalance_penalty
    
    # Foster diversity in heuristic selection to escape local optima
    diversity_factor = torch.abs(torch.randn_like(demands)) * 0.1
    heuristics += diversity_factor
    
    # Adapt penalties dynamically based on the cumulative demand
    dynamic_penalty = -torch.log1p(torch.abs(demands - total_capacity / n) - 1e-8)
    heuristics *= dynamic_penalty
    
    return heuristics
```
