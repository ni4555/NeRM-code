```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    cumulative_demand = torch.cumsum(demands, dim=0)
    
    # Vectorized overflow penalty for edges that lead to overflow capacity
    overflow_penalty = -torch.log1p(torch.abs(cumulative_demand + demands - total_capacity) - 1e-8)
    
    # Scale demand penalty based on how close the cumulative demand is to the capacity
    demand_penalty = capacity_penalty * (1 + (total_capacity - cumulative_demand) / total_capacity)
    
    # Scale distance penalty based on the cumulative demand, encouraging closer stops for higher demand
    distance_penalty = distance_penalty * (1 + cumulative_demand)
    
    # Calculate the remaining capacity
    remaining_capacity = total_capacity - cumulative_demand
    
    # Incentivize using remaining capacity
    capacity_incentive = torch.exp(-remaining_capacity / total_capacity)
    
    # Combine the penalties with the incentives, balancing demand and distance penalties
    heuristics = demand_penalty + distance_penalty + overflow_penalty * capacity_incentive
    heuristics = heuristics - (heuristics == torch.inf).float() * float('inf')
    
    # Add an incentive for the depot (start and end point), which is a vector of ones for this case
    heuristics = heuristics + (torch.arange(n) == 0).float().unsqueeze(0)
    
    return heuristics
```
