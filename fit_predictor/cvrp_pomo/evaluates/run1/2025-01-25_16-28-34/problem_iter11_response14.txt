```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    heuristics = torch.zeros_like(distance_matrix)
    
    # Calculate the sum of demands for each edge (i, j)
    edge_demand_sum = (demands[:, None] + demands[None, :]) * distance_matrix
    
    # Calculate the average demand per edge
    average_demand_per_edge = edge_demand_sum / (distance_matrix ** 2)
    
    # Introduce a refined heuristic that considers both overloading and underloading penalties
    heuristics = torch.log1p(average_demand_per_edge) - torch.log1p(total_capacity)
    
    # Calculate penalties for overloading and underloading
    overload_penalty = torch.clamp(torch.abs(heuristics) * 1000, min=0)  # Increase penalty for overloading
    underload_penalty = torch.clamp(torch.abs(1 - heuristics) * 500, min=0)  # Decrease penalty for underloading
    
    # Dynamic adjustment of penalties based on the average demand ratio
    penalty_ratio = torch.clamp((average_demand_per_edge / total_capacity), min=0, max=1)
    dynamic_penalty = penalty_ratio * (overload_penalty + underload_penalty)
    
    # Apply the dynamic penalty to the heuristics
    heuristics -= dynamic_penalty
    
    # Maintain diversity by adding a small perturbation
    perturbation = torch.rand_like(heuristics)
    perturbation = torch.where(average_demand_per_edge < 0.5, perturbation * 2, perturbation)  # Larger perturbation for lower average demand edges
    heuristics -= perturbation * 0.05
    
    # Encourage exploration in unexplored regions by reducing penalties in the farthest edges
    farthest_edges = torch.topk(distance_matrix.abs(), k=int(n/10))[1]
    heuristics[farthest_edges] += (dynamic_penalty.max() / 5)  # Small bonus for exploration
    
    # Ensure the heuristics are negative for undesirable edges
    heuristics[distance_matrix == 0] = 0
    heuristics[heuristics >= 0] = -torch.abs(heuristics[heuristics >= 0])
    
    return heuristics
```
