```python
import torch

def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    heuristics = torch.zeros_like(distance_matrix)
    
    # Calculate the sum of demands for each edge (i, j)
    edge_demand_sum = (demands[:, None] + demands[None, :]) * distance_matrix
    
    # Calculate the average demand per edge
    average_demand_per_edge = edge_demand_sum / (distance_matrix ** 2)
    
    # Introduce a more refined heuristic that considers the balance between overloading and underloading
    heuristics = torch.log1p(average_demand_per_edge) - torch.log1p(total_capacity)
    
    # Calculate penalties for overloading and underloading
    overload_penalty = torch.abs(heuristics)
    underload_penalty = torch.abs(1 - heuristics)
    
    # Dynamic penalties based on the ratio of average demand to total capacity
    penalty_ratio = torch.clamp((average_demand_per_edge / total_capacity), min=0, max=1)
    dynamic_penalty = (penalty_ratio ** 2) * (overload_penalty + underload_penalty)
    
    # Apply the dynamic penalty to the heuristics
    heuristics -= dynamic_penalty
    
    # Ensure the heuristics are negative for undesirable edges
    heuristics[distance_matrix == 0] = 0
    heuristics[heuristics >= 0] = -torch.abs(heuristics[heuristics >= 0])
    
    # Encourage diversity by adding a perturbation with adaptive strength
    perturbation_strength = torch.rand_like(heuristics)
    perturbation_strength = torch.clamp(perturbation_strength, 0.05, 0.2)  # Adjust the range for perturbation strength
    perturbation = torch.rand_like(heuristics)
    heuristics -= perturbation * perturbation_strength
    
    # Integrate PSO-inspired exploration and exploitation by adjusting the heuristic values
    # Assuming a global best and current best are available
    global_best = torch.full_like(heuristics, float('inf'))
    current_best = torch.full_like(heuristics, float('inf'))
    
    # Exploration factor
    exploration_factor = torch.clamp(1 - (current_best / global_best), min=0, max=1)
    
    # Apply exploration and exploitation
    heuristics = heuristics * exploration_factor + global_best * (1 - exploration_factor)
    
    return heuristics
```
