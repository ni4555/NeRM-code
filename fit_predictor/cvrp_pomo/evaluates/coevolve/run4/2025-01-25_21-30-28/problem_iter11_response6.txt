```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.shape[0]
    total_capacity = demands.sum()
    normalized_demands = demands / total_capacity

    # Inverse distance heuristic: edges with shorter distances are more promising
    inverse_distance = 1.0 / (distance_matrix + 1e-8)

    # Demand normalization heuristic: edges with normalized demand closer to 1 are more promising
    demand_diff = torch.abs(normalized_demands - 1.0)
    demand_weight = 1.0 / (demand_diff + 1e-8)

    # Heuristic range adjustment: adaptively modify search space based on performance
    # Use previously evaluated solutions to inform the adjustment
    # For simplicity, use the mean distance as a proxy for performance
    mean_distance = distance_matrix.mean()
    heuristic_range = 1.0 / (distance_matrix + mean_distance + 1e-8)

    # Load balancing strategy: prioritize edges with demand close to capacity
    load_balance = 1.0 / (1 + torch.abs(torch.linspace(0, total_capacity, steps=n) - normalized_demands))

    # Balance heuristics dynamically: use a weighted sum to combine heuristics
    weight_inverse_distance = 0.5
    weight_demand_weight = 0.3
    weight_heuristic_range = 0.2
    weight_load_balance = 0.4

    # Combine heuristics using domain knowledge and weights
    combined_heuristic = (inverse_distance * weight_inverse_distance +
                          demand_weight * weight_demand_weight +
                          heuristic_range * weight_heuristic_range +
                          load_balance * weight_load_balance)

    # Normalize the combined heuristic to ensure stability
    combined_heuristic = combined_heuristic / combined_heuristic.sum()

    # Mutation: Introduce a random perturbation to explore new solutions
    mutation_factor = 0.01
    random_factor = torch.rand_like(combined_heuristic)
    mutated_heuristic = combined_heuristic + mutation_factor * (random_factor - 0.5)

    # Mutation: Introduce a penalty for large deviations from the mean
    penalty_factor = torch.clamp(torch.abs(mutated_heuristic - combined_heuristic) * 10, max=10.0)
    mutated_heuristic -= penalty_factor

    # Mutation: Introduce a bonus for beneficial deviations from the mean
    bonus_factor = torch.clamp(torch.abs(mutated_heuristic - combined_heuristic) * 5, max=10.0)
    mutated_heuristic += bonus_factor

    # Normalize the mutated heuristic to ensure stability
    mutated_heuristic = mutated_heuristic / mutated_heuristic.sum()

    # Clamp values to a reasonable range to avoid extreme values
    mutated_heuristic = torch.clamp(mutated_heuristic, min=-1.0, max=1.0)

    return mutated_heuristic
```
