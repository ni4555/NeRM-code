{
  "generation": 5,
  "description": "Design an optimization heuristic for the Capacitated Vehicle Routing Problem (CVRP) that integrates a normalized demand and distance adjustment mechanism with a specific inverse distance heuristic for initial customer assignment. The heuristic should incorporate a demand penalty function that scales the cost of assigning high-demand customers to vehicles near their capacity limit. To ensure efficient route assignments, the heuristic must utilize a Genetic Algorithm (GA) for iterative route improvement, a Simulated Annealing (SA) method to navigate past local optima, and an Ant Colony Optimization (ACO) for path exploration. The algorithm must be equipped with a real-time rerouting capability to adapt to dynamic changes in customer demands and vehicle availability within a predefined response time frame. The heuristic must explicitly define penalty functions, avoid general objectives, specify all employed heuristics and algorithms, and adhere to constraints such as vehicle capacity, demand, and real-time rerouting requirements to minimize total route distance and enhance operational efficiency.",
  "failed_solutions": [
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    n = distance_matrix.shape[0]\n    # Normalize the distance matrix\n    distance_matrix = distance_matrix / distance_matrix.max()\n    \n    # Calculate the normalized demand\n    normalized_demands = demands / demands.sum()\n    \n    # Demand penalty function: scale the cost of assigning high-demand customers\n    demand_penalty = normalized_demands * 0.1  # Example scaling factor\n    \n    # Calculate the inverse distance heuristic\n    inverse_distance = 1 / distance_matrix\n    \n    # Combine the inverse distance heuristic and the demand penalty\n    heuristics = inverse_distance - demand_penalty\n    \n    # Ensure that the heuristics matrix has negative values for undesirable edges\n    heuristics = heuristics - heuristics.max() - 1\n    \n    return heuristics",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 52, in pre_forward\n    assert not torch.isnan(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_5\\stdout_0.txt",
      "code_file": "coevolve\\generation_5\\code_0.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demand by total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Demand penalty function: higher penalty for higher normalized demand\n    demand_penalty = normalized_demands * 10  # Example factor, adjust as needed\n    \n    # Inverse distance heuristic: lower distance, higher heuristic value\n    inverse_distance = 1 / (distance_matrix ** 2)  # Squared to ensure non-zero values\n    \n    # Combine both heuristics\n    combined_heuristic = inverse_distance - demand_penalty\n    \n    # Avoid negative values by clamping\n    combined_heuristic = torch.clamp(combined_heuristic, min=0)\n    \n    return combined_heuristic",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 53, in pre_forward\n    assert not torch.isinf(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_5\\stdout_2.txt",
      "code_file": "coevolve\\generation_5\\code_2.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by total vehicle capacity (assuming total_capacity is given as a parameter)\n    # For this example, we'll assume total_capacity is the sum of all demands\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Demand penalty function: higher demand closer to capacity limit gets a higher penalty\n    demand_penalty = (1 - normalized_demands) * 1000\n\n    # Inverse distance heuristic: closer nodes are more promising\n    inverse_distance = 1 / distance_matrix\n\n    # Combine demand penalty and inverse distance heuristic\n    heuristic_values = inverse_distance - demand_penalty\n\n    # Replace negative values with zeros (to avoid including undesirable edges)\n    heuristic_values[heuristic_values < 0] = 0\n\n    return heuristic_values",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 53, in pre_forward\n    assert not torch.isinf(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_5\\stdout_4.txt",
      "code_file": "coevolve\\generation_5\\code_4.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the distance matrix to have a range between 0 and 1\n    distance_matrix = (distance_matrix - distance_matrix.min()) / (distance_matrix.max() - distance_matrix.min())\n    \n    # Normalize the demands to be between 0 and 1\n    normalized_demands = demands / demands.sum()\n    \n    # Calculate the inverse distance heuristic\n    inverse_distance = 1 / distance_matrix\n    \n    # Apply a demand penalty function to high-demand customers\n    demand_penalty = demands * (1 - demands)  # A simple quadratic penalty function\n    \n    # Combine the heuristics\n    combined_heuristic = inverse_distance - demand_penalty\n    \n    # Normalize the combined heuristic to have a range between 0 and 1\n    combined_heuristic = (combined_heuristic - combined_heuristic.min()) / (combined_heuristic.max() - combined_heuristic.min())\n    \n    return combined_heuristic",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 52, in pre_forward\n    assert not torch.isnan(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_5\\stdout_6.txt",
      "code_file": "coevolve\\generation_5\\code_6.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the distance matrix to ensure no distance is zero\n    distance_matrix = distance_matrix - torch.min(distance_matrix)\n    \n    # Calculate normalized demand\n    normalized_demands = demands / torch.sum(demands)\n    \n    # Define the demand penalty function\n    def demand_penalty(demand):\n        # High demand customers close to capacity have a higher penalty\n        return demand * torch.clamp((1 - demand), min=0, max=1)\n    \n    # Apply the demand penalty function to the demand vector\n    demand_penalty_vector = torch.vectorized(demand_penalty)(normalized_demands)\n    \n    # Compute the heuristic values based on the inverse distance and demand penalty\n    heuristic_matrix = (1 / distance_matrix) * demand_penalty_vector\n    \n    # Ensure the heuristic values are negative for undesirable edges\n    heuristic_matrix[distance_matrix == 0] = float('-inf')\n    \n    return heuristic_matrix",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 49, in pre_forward\n    self.attention_bias = torch.stack([\n                                      ^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 50, in <listcomp>\n    heuristics(distance_matrices[i], all_node_demands[i]) for i in range(all_nodes_xy.size(0))\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\gpt.py\", line 17, in heuristics_v2\n    \n  File \"D:\\Conda_data\\envs\\reevo\\Lib\\site-packages\\torch\\__init__.py\", line 2562, in __getattr__\n    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\nAttributeError: module 'torch' has no attribute 'vectorized'\n",
      "stdout_file": "coevolve\\generation_5\\stdout_7.txt",
      "code_file": "coevolve\\generation_5\\code_7.py"
    }
  ]
}