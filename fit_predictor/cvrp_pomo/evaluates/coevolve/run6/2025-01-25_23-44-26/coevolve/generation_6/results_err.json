{
  "generation": 6,
  "description": "Develop a novel heuristic approach for solving the Capacitated Vehicle Routing Problem (CVRP) that integrates a normalization process for customer demand and distance. The heuristic should initially utilize an Inverse Distance Heuristic (IDH) to assign customers to vehicles based on the reciprocal of their distance from the depot, ensuring a balanced distribution. To respect capacity constraints, a demand penalty function will be employed, increasing the cost of assigning high-demand customers to vehicles near their capacity limits. The solution will further incorporate a combination of a Genetic Algorithm (GA) for iterative route improvement, Simulated Annealing (SA) to escape local optima, and Ant Colony Optimization (ACO) for path exploration and learning. This hybrid framework must be equipped with a real-time rerouting mechanism to adapt to dynamic changes in customer demands and vehicle availability within a predefined response time frame, thereby maintaining optimized vehicle assignments and route distances.",
  "failed_solutions": [
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Calculate inverse distance heuristic values\n    inv_distance = 1.0 / (distance_matrix ** 2)\n    \n    # Calculate demand penalty based on normalized demand\n    demand_penalty = (1 - normalized_demands) * (1 + 0.1 * demands)\n    \n    # Combine inverse distance and demand penalty\n    heuristic_values = inv_distance - demand_penalty\n    \n    return heuristic_values",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 53, in pre_forward\n    assert not torch.isinf(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_6\\stdout_1.txt",
      "code_file": "coevolve\\generation_6\\code_1.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Inverse Distance Heuristic (IDH): Assign customers based on the reciprocal of their distance\n    idh_scores = 1.0 / distance_matrix\n    \n    # Demand penalty function: Increase cost for customers near vehicle capacity\n    demand_penalty = (normalized_demands * distance_matrix).sum(dim=1)\n    demand_penalty = demand_penalty.unsqueeze(1) * distance_matrix\n    \n    # Combine IDH scores with demand penalty to get initial heuristics\n    combined_heuristics = idh_scores - demand_penalty\n    \n    return combined_heuristics",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 53, in pre_forward\n    assert not torch.isinf(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_6\\stdout_2.txt",
      "code_file": "coevolve\\generation_6\\code_2.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Calculate the inverse distance heuristic (IDH) values\n    idh_values = 1 / distance_matrix\n\n    # Apply demand penalty function\n    demand_penalty = normalized_demands.unsqueeze(1) * normalized_demands.unsqueeze(0)\n    demand_penalty = torch.clamp(demand_penalty, min=0, max=1)  # Ensure non-negative values\n\n    # Combine IDH and demand penalty to get initial heuristics\n    heuristics = idh_values - demand_penalty\n\n    return heuristics",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 53, in pre_forward\n    assert not torch.isinf(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_6\\stdout_3.txt",
      "code_file": "coevolve\\generation_6\\code_3.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the demands by the total vehicle capacity\n    total_capacity = torch.sum(demands)\n    normalized_demands = demands / total_capacity\n\n    # Calculate the inverse distance heuristic (IDH) values\n    idh_values = 1.0 / distance_matrix\n\n    # Calculate the demand penalty function\n    # Increase the cost for edges leading to vehicles that are near their capacity limits\n    # We use a simple linear penalty here, but this can be adjusted as needed\n    capacity_penalty_threshold = 0.8  # Vehicles are considered near capacity at 80% of capacity\n    demand_penalty = normalized_demands * (1.0 - capacity_penalty_threshold)\n    demand_penalty = torch.where(demand_penalty < 0, torch.zeros_like(demand_penalty), demand_penalty)\n    demand_penalty = demand_penalty * torch.max(idh_values)\n\n    # Combine IDH and demand penalty to get the heuristic values\n    heuristic_values = idh_values - demand_penalty\n\n    return heuristic_values",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 52, in pre_forward\n    assert not torch.isnan(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_6\\stdout_4.txt",
      "code_file": "coevolve\\generation_6\\code_4.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize customer demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Inverse Distance Heuristic (IDH) - assign customers based on the reciprocal of their distance\n    # Ensure that the distance matrix is squared to avoid double counting\n    distance_matrix_squared = distance_matrix ** 2\n    idh_scores = 1 / distance_matrix_squared\n\n    # Demand penalty function - increase cost for high-demand customers near capacity limits\n    # Calculate the sum of demands for each vehicle considering the depot\n    vehicle_capacities = torch.clamp(demands.cumsum() - demands[0], min=0)\n    demand_penalty = (vehicle_capacities / total_capacity) ** 2\n\n    # Combine IDH scores with demand penalty to get the heuristic scores\n    heuristic_scores = idh_scores - demand_penalty\n\n    # Ensure that the heuristic scores are negative for undesirable edges and positive for promising ones\n    # This is done by adding a large constant to the negative values and subtracting it from the positive values\n    large_constant = 1e6\n    heuristic_scores = torch.where(heuristic_scores < 0, large_constant + heuristic_scores, large_constant - heuristic_scores)\n\n    return heuristic_scores",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 49, in pre_forward\n    self.attention_bias = torch.stack([\n                                      ^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 50, in <listcomp>\n    heuristics(distance_matrices[i], all_node_demands[i]) for i in range(all_nodes_xy.size(0))\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\gpt.py\", line 16, in heuristics_v2\n    demand_penalty = demands / demands.clamp(min=1e-8)  # Avoid division by zero\n                                     ^^^^^^^^^^^^^^^^\nTypeError: cumsum() received an invalid combination of arguments - got (), but expected one of:\n * (int dim, *, torch.dtype dtype = None)\n * (name dim, *, torch.dtype dtype = None)\n\n",
      "stdout_file": "coevolve\\generation_6\\stdout_7.txt",
      "code_file": "coevolve\\generation_6\\code_7.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize customer demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Calculate the inverse distance heuristic (IDH) using reciprocal distance\n    idh_values = 1.0 / distance_matrix\n\n    # Combine IDH with normalized demand to create initial heuristics\n    combined_heuristics = idh_values * normalized_demands\n\n    # Calculate the demand penalty function\n    demand_penalty = demands / demands.clamp(min=1e-8)  # Avoid division by zero\n\n    # Increase the cost of assigning high-demand customers to vehicles near their capacity limits\n    combined_heuristics = combined_heuristics + demand_penalty\n\n    return combined_heuristics",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 52, in pre_forward\n    assert not torch.isnan(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_6\\stdout_8.txt",
      "code_file": "coevolve\\generation_6\\code_8.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize customer demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Calculate the inverse distance heuristic (IDH) values\n    idh_values = 1 / distance_matrix\n\n    # Incorporate demand penalty function\n    demand_penalty = (1 + 0.1 * (normalized_demands - 1))  # Adjust the penalty factor as needed\n\n    # Combine IDH and demand penalty to get the heuristic values\n    heuristic_values = idh_values * demand_penalty\n\n    # Add a small constant to avoid division by zero\n    heuristic_values = heuristic_values + 1e-6\n\n    return heuristic_values",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 109, in _test_one_batch\n    self.model.pre_forward(reset_state)\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 53, in pre_forward\n    assert not torch.isinf(self.attention_bias).any()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
      "stdout_file": "coevolve\\generation_6\\stdout_9.txt",
      "code_file": "coevolve\\generation_6\\code_9.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Inverse Distance Heuristic (IDH) - assign customers based on the reciprocal of their distance\n    # We subtract the distances to ensure higher weights for closer customers\n    idh_weights = 1 / (distance_matrix[:, 1:] - distance_matrix[:, 0][:, None])\n    idh_weights[distance_matrix[:, 1:] - distance_matrix[:, 0][:, None] == 0] = 0  # Avoid division by zero\n    \n    # Demand penalty function - increase cost for assigning high-demand customers to vehicles near capacity\n    demand_penalty = normalized_demands[1:] * demands[1:]\n    \n    # Combine IDH and demand penalty into a single heuristic matrix\n    # We add the penalties to the weights since we want to penalize higher costs\n    heuristic_matrix = idh_weights + demand_penalty\n    \n    return heuristic_matrix",
      "fitness": Infinity,
      "execution_success": false,
      "error": "Traceback (most recent call last):\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 140, in <module>\n    avg_obj = main()\n              ^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2/problems/cvrp_pomo/eval.py\", line 94, in main\n    avg_obj = tester.run()\n              ^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 71, in run\n    score, aug_score = self._test_one_batch(batch_size)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPTester.py\", line 115, in _test_one_batch\n    selected, _ = self.model(state)\n                  ^^^^^^^^^^^^^^^^^\n  File \"D:\\Conda_data\\envs\\reevo\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Conda_data\\envs\\reevo\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 101, in forward\n    probs = self.decoder(encoded_last_node, state.load, ninf_mask=state.ninf_mask, attention_bias=attention_bias_current_node)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Conda_data\\envs\\reevo\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Conda_data\\envs\\reevo\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ProgramLanguages\\Programs\\Python\\code-gen\\reevo_2\\problems\\cvrp_pomo\\CVRPModel.py\", line 294, in forward\n    score = score + attention_bias if attention_bias is not None else score\n            ~~~~~~^~~~~~~~~~~~~~~~\nRuntimeError: The size of tensor a (501) must match the size of tensor b (500) at non-singleton dimension 2\n",
      "stdout_file": "coevolve\\generation_6\\stdout_11.txt",
      "code_file": "coevolve\\generation_6\\code_11.py"
    }
  ]
}