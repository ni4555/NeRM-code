```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    total_demand = demands.sum()
    normalized_demands = demands / total_demand
    
    # Adjust weights for dynamic programming and demand heuristics
    dp_weight = 0.6
    demand_weight = 0.4
    
    # Implement a more sophisticated dynamic programming approach
    dp = torch.zeros((len(demands), len(demands)))
    for d in range(1, len(demands)):
        dp[d, d-1:] = torch.cat((dp[d-1, d-1:], distance_matrix[d-1, d-1:]), dim=0)
    
    # Calculate a more refined lower bound using dynamic programming
    lower_bound = torch.min(dp[:, 0], dp[0, :])
    
    # Use a combination of lower bound and demand to estimate edge potential
    epsilon = 1e-8
    edge_potential = (lower_bound / (distance_matrix + epsilon)) * torch.pow(normalized_demands, demand_weight)
    edge_potential = edge_potential * dp_weight + (1 / (distance_matrix + epsilon)) * torch.pow(normalized_demands, 0.5) * (1 - dp_weight)
    
    # Apply penalties based on demand and distance
    edge_potential = edge_potential - (edge_potential * 0.1 * (demands > 1.5).float())
    edge_potential = edge_potential + (edge_potential * 0.05 * (distance_matrix < 10).float())
    
    # Introduce a local search heuristic to adjust the potential
    for i in range(len(demands)):
        for j in range(i + 1, len(demands)):
            if distance_matrix[i, j] < 20:
                # Simulate a swap between i and j
                temp_demand = demands[i]
                demands[i] = demands[j]
                demands[j] = temp_demand
                local_potential = heuristics_v2(distance_matrix, demands)
                # Revert the swap if the local potential is better
                if local_potential[i, j] < edge_potential[i, j]:
                    edge_potential[i, j] = local_potential[i, j]
                demands[i] = temp_demand
                demands[j] = temp_demand
    
    return edge_potential
```
