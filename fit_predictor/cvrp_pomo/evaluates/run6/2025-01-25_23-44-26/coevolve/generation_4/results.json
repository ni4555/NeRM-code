{
  "generation": 4,
  "description": "The objective is to develop a robust heuristic solution for the Capacitated Vehicle Routing Problem (CVRP) that employs specific optimization techniques. The solution should incorporate a normalization process for demand and distance to ensure consistency in problem scale. An inverse distance heuristic will be used to initially assign customers to vehicles based on the reciprocal of their distance from the depot. To maintain capacity constraints, a demand penalty function will be implemented, which increases the cost of assigning customers with high demands to vehicles that are already close to capacity. The heuristic framework will integrate a Genetic Algorithm for iterative route improvement, a Simulated Annealing method to avoid local optima, and an Ant Colony Optimization algorithm for learning and exploring efficient paths. The algorithm should be capable of handling dynamic changes in customer demands and vehicle availability by utilizing a real-time rerouting mechanism that responds to updates within a predefined time frame, ensuring that the vehicle assignments and route distances remain optimized.",
  "solutions": [
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by total vehicle capacity (assuming demands are already normalized by capacity)\n    total_capacity = demands.sum()\n    \n    # Inverse distance heuristic: calculate the reciprocal of the distance\n    inv_distance = 1.0 / (distance_matrix + 1e-8)  # Adding a small constant to avoid division by zero\n    \n    # Demand penalty function: increase cost for edges leading to vehicles close to capacity\n    # We calculate the penalty based on the reciprocal of the demand to favor lower demand customers\n    demand_penalty = 1.0 / (demands + 1e-8)\n    capacity_penalty = (demands / total_capacity) * (1 - 1 / (demands + 1e-8))\n    penalty = capacity_penalty * (inv_distance + 1e-8)\n    \n    # Combine heuristics: inverse distance and demand penalty\n    combined_heuristics = inv_distance - penalty\n    \n    # Ensure negative values for undesirable edges and positive values for promising ones\n    combined_heuristics = combined_heuristics.clamp(min=-1e8, max=1e8)\n    \n    return combined_heuristics",
      "fitness": 50.61586380004883,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_4\\stdout_8.txt",
      "code_file": "coevolve\\generation_4\\code_8.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Compute the inverse distance heuristic\n    inv_distance = 1 / (distance_matrix + 1e-8)  # Adding a small constant to avoid division by zero\n\n    # Incorporate demand penalty function\n    demand_penalty = normalized_demands * (1 + demands * 0.1)  # Increase penalty for high demands\n\n    # Combine the inverse distance and demand penalty to get the heuristic values\n    heuristic_values = inv_distance - demand_penalty\n\n    return heuristic_values",
      "fitness": 50.694759368896484,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_4\\stdout_1.txt",
      "code_file": "coevolve\\generation_4\\code_1.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Calculate the inverse distance for each edge\n    inv_distance = 1 / (distance_matrix + 1e-8)  # Adding a small constant to avoid division by zero\n    \n    # Calculate the demand penalty for each edge\n    demand_penalty = normalized_demands.unsqueeze(1) * normalized_demands.unsqueeze(0)\n    \n    # Combine inverse distance and demand penalty to get the heuristic values\n    heuristic_values = inv_distance - demand_penalty\n    \n    return heuristic_values",
      "fitness": 50.694759368896484,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_4\\stdout_3.txt",
      "code_file": "coevolve\\generation_4\\code_3.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Calculate the inverse distance heuristic\n    inverse_distance = 1 / (distance_matrix + 1e-8)  # Adding a small constant to avoid division by zero\n    \n    # Calculate the demand penalty function\n    demand_penalty = normalized_demands * (1 - demands / total_capacity)\n    \n    # Combine the inverse distance and demand penalty to get the heuristic values\n    heuristics = inverse_distance - demand_penalty\n    \n    return heuristics",
      "fitness": 50.694759368896484,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_4\\stdout_11.txt",
      "code_file": "coevolve\\generation_4\\code_11.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize distance matrix to be in terms of inverse distance\n    normalized_distance = 1.0 / (distance_matrix + 1e-8)  # Add a small constant to avoid division by zero\n    \n    # Normalize demands by total vehicle capacity (assumed to be 1 for simplicity)\n    normalized_demands = demands / demands.sum()\n    \n    # Calculate the penalty for high demand customers\n    demand_penalty = 1 + 0.5 * (demands - demands.mean())\n    \n    # Combine inverse distance and demand penalty\n    combined_heuristic = normalized_distance * demand_penalty\n    \n    return combined_heuristic",
      "fitness": 50.97673416137695,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_4\\stdout_7.txt",
      "code_file": "coevolve\\generation_4\\code_7.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize demands by total vehicle capacity\n    total_capacity = torch.sum(demands)\n    normalized_demands = demands / total_capacity\n\n    # Inverse distance heuristic\n    inverse_distances = 1 / (distance_matrix + 1e-8)  # Adding a small constant to avoid division by zero\n\n    # Demand penalty function\n    demand_penalty = normalized_demands * (1 + 0.1 * (demands > 0.5).float())  # Increase cost for high demands\n\n    # Combine inverse distance and demand penalty\n    heuristics = -inverse_distances + demand_penalty\n\n    return heuristics",
      "fitness": 61.3948860168457,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_4\\stdout_5.txt",
      "code_file": "coevolve\\generation_4\\code_5.py"
    }
  ]
}