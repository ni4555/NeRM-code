{
  "generation": 7,
  "description": "Develop an advanced heuristic for the Capacitated Vehicle Routing Problem (CVRP) that leverages normalization to homogenize demand and distance metrics. The heuristic employs a hybrid approach, initially using an Inverse Distance heuristic for customer assignment, then integrating a demand-penalty mechanism to deter overloading vehicles. To enhance route quality, the algorithm incorporates a Genetic Algorithm (GA) for iterative refinement, Simulated Annealing (SA) to evade local minima, and Ant Colony Optimization (ACO) to uncover optimal paths. The system must be equipped with a robust real-time rerouting capability that swiftly adjusts vehicle assignments and routes in response to evolving customer demands and vehicle capacities within a stringent response time limit. The primary objective is to minimize the total travel distance, adhere to capacity limits, and ensure a scalable and responsive solution for fluctuating CVRP scenarios.",
  "solutions": [
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    n = distance_matrix.shape[0]\n    total_capacity = demands.sum()\n    demands_normalized = demands / total_capacity\n    \n    # Inverse Distance heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-10)  # Adding a small value to avoid division by zero\n    \n    # Demand-penalty mechanism\n    demand_penalty = demands_normalized - demands_normalized.min()\n    \n    # Combine heuristics\n    combined_heuristic = inverse_distance * demand_penalty\n    \n    return combined_heuristic",
      "fitness": 49.78913116455078,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_10.txt",
      "code_file": "coevolve\\generation_7\\code_10.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    n = distance_matrix.shape[0]\n    \n    # Inverse Distance Heuristic (IDH)\n    inverse_distance = 1 / (distance_matrix + 1e-10)  # Adding a small value to avoid division by zero\n    \n    # Demand-penalty mechanism\n    demand_penalty = -demands\n    \n    # Combine IDH and demand-penalty\n    combined_heuristic = inverse_distance + demand_penalty\n    \n    # Normalize the combined heuristic to ensure non-negative values\n    min_val = combined_heuristic.min()\n    max_val = combined_heuristic.max()\n    normalized_heuristic = (combined_heuristic - min_val) / (max_val - min_val)\n    \n    return normalized_heuristic",
      "fitness": 49.88407897949219,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_0.txt",
      "code_file": "coevolve\\generation_7\\code_0.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Calculate inverse distance heuristic\n    inv_distance = 1.0 / (distance_matrix + 1e-8)  # Adding a small constant to avoid division by zero\n\n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Calculate demand-penalty heuristic\n    demand_penalty = -demands\n\n    # Combine the inverse distance and demand-penalty heuristics\n    combined_heuristic = inv_distance * normalized_demands + demand_penalty\n\n    return combined_heuristic",
      "fitness": 49.914588928222656,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_9.txt",
      "code_file": "coevolve\\generation_7\\code_9.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the demand vector by the sum of demands to ensure each demand is relative to the total capacity\n    total_demand = demands.sum().item()\n    normalized_demands = demands / total_demand\n\n    # Calculate the inverse distance heuristic\n    # Assuming the distance matrix is already precomputed and contains positive values\n    min_distance = distance_matrix.min(dim=1, keepdim=True)[0]\n    max_distance = distance_matrix.max(dim=1, keepdim=True)[0]\n    inverse_distance = 1 / (min_distance + max_distance)\n\n    # Integrate demand-penalty mechanism to deter overloading vehicles\n    demand_penalty = -normalized_demands * 1000  # Example penalty factor\n\n    # Combine the inverse distance and demand-penalty\n    combined_heuristic = inverse_distance + demand_penalty\n\n    return combined_heuristic",
      "fitness": 50.34738540649414,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_1.txt",
      "code_file": "coevolve\\generation_7\\code_1.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the distance matrix to create an inverse distance heuristic\n    inv_distance = 1.0 / (distance_matrix + 1e-6)  # Adding a small constant to avoid division by zero\n    \n    # Normalize the demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Create a demand-penalty matrix to deter overloading vehicles\n    demand_penalty = normalized_demands * 1000  # Adjust the penalty factor as needed\n    \n    # Combine the inverse distance and demand-penalty to get the heuristic matrix\n    heuristic_matrix = inv_distance - demand_penalty\n    \n    return heuristic_matrix",
      "fitness": 50.360774993896484,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_4.txt",
      "code_file": "coevolve\\generation_7\\code_4.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Normalize the demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n\n    # Compute the inverse distance heuristic\n    # The heuristic is based on the inverse of the distance, so we take the reciprocal of the distance matrix\n    # and subtract it from 1 to get negative values for closer customers\n    inverse_distance = 1 - (distance_matrix / distance_matrix.max())\n\n    # Demand-penalty mechanism: penalize edges with high demand\n    demand_penalty = normalized_demands * distance_matrix\n\n    # Combine the inverse distance heuristic with the demand penalty\n    combined_heuristic = inverse_distance - demand_penalty\n\n    # Ensure that all values are within a reasonable range (e.g., between -1 and 1)\n    combined_heuristic = torch.clamp(combined_heuristic, min=-1, max=1)\n\n    return combined_heuristic",
      "fitness": 50.571739196777344,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_8.txt",
      "code_file": "coevolve\\generation_7\\code_8.py"
    },
    {
      "code": "import torch\nimport torch\n\ndef heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:\n    # Calculate the inverse distance matrix\n    inv_distance_matrix = 1 / (distance_matrix + 1e-8)  # Add a small value to avoid division by zero\n    \n    # Normalize demands by the total vehicle capacity\n    total_capacity = demands.sum()\n    normalized_demands = demands / total_capacity\n    \n    # Apply the demand-penalty mechanism\n    demand_penalty = demands * 0.1  # Adjust the penalty factor as needed\n    \n    # Calculate the initial heuristic value based on inverse distance and demand-penalty\n    heuristic_values = inv_distance_matrix * (1 - normalized_demands) + demand_penalty\n    \n    return heuristic_values",
      "fitness": 50.68423080444336,
      "execution_success": true,
      "error": null,
      "stdout_file": "coevolve\\generation_7\\stdout_2.txt",
      "code_file": "coevolve\\generation_7\\code_2.py"
    }
  ]
}