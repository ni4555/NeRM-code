```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    heuristic = np.zeros(n)

    # Deep reinforcement learning component (simplified)
    # Assuming a pre-trained model that provides a score for each item
    # Here we simulate this with a random number generator for demonstration
    model_scores = np.random.rand(n)

    # Adaptive constraint-driven filtering
    feasible_indices = np.arange(n)
    while feasible_indices.size > 0:
        total_weight = np.sum(weight[feasible_indices])
        if total_weight <= 1:
            break
        # Find the item that, when removed, allows the rest to be feasible
        for i in reversed(range(feasible_indices.size)):
            if np.sum(weight[feasible_indices[:i]]) + weight[feasible_indices[i]] <= 1:
                feasible_indices = feasible_indices[:i]
                break
        else:
            # If no such item is found, it means the current set is infeasible
            break

    # Update heuristics based on the model scores of feasible items
    heuristic[feasible_indices] = model_scores[feasible_indices]

    # Particle swarm optimization for evolutionary swarm intelligence
    # Simulate the local best and global best positions
    local_best_scores = np.max(prize[feasible_indices]) * heuristic[feasible_indices]
    global_best_score = np.max(prize) * np.max(heuristic)

    # Update heuristic based on the factors
    heuristic[feasible_indices] *= (prize[feasible_indices] / (local_best_scores + 1e-6)) * \
                                   ((global_best_score - prize[feasible_indices]) / (global_best_score + 1e-6))

    # Sparsify the heuristics by setting unpromising elements to zero
    heuristic[heuristic < 0.5] = 0

    return heuristic
```
