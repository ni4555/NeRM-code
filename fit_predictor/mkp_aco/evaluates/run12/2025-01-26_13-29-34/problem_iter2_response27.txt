```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]
    heuristic = np.zeros((n,))

    # Deep reinforcement learning for real-time decision-making
    rl_model = np.random.rand(n)
    rl_model = rl_model / np.sum(rl_model)  # Normalize to probability distribution

    # Adaptive constraint-driven filtering parameters
    alpha = 0.1  # Learning rate for adaptive filtering
    feasibility_threshold = 0.95  # Threshold for feasibility

    # Particle swarm optimization parameters
    particle_best_positions = np.copy(prize)
    particle_best_scores = np.copy(prize)
    global_best_position = np.copy(prize)
    global_best_score = np.min(prize)  # Start with the minimum to maximize later

    # Initialize swarm positions randomly
    swarm_positions = np.random.rand(n, n)
    swarm_velocities = np.random.rand(n, n)

    # Define a function to calculate the feasibility of a candidate solution
    def is_feasible(candidate, current_weight):
        return np.all(candidate <= 1 - current_weight)

    # Define a function to update the swarm positions and best scores
    def update_swarm(particles, velocities, best_positions, best_scores):
        for i in range(n):
            velocities[i] = 0.5 * velocities[i] + 0.5 * (best_positions[i] - particles[i])
            particles[i] += velocities[i]
            # Ensure particles do not exceed the weight constraint
            particles[i] = np.clip(particles[i], 0, 1)
            # Evaluate the fitness of the new particle position
            score = np.sum(particles[i] * prize)
            if score > best_scores[i]:
                best_scores[i] = score
                best_positions[i] = particles[i]

    # Main loop for heuristic computation
    for episode in range(1000):
        # Deep reinforcement learning step
        for i in range(n):
            if np.random.rand() < rl_model[i]:
                # Simulate item selection based on RL model
                for j in range(m):
                    if weight[i, j] > feasibility_threshold:
                        rl_model[i] *= (1 - alpha)
                        break

        # Adaptive constraint-driven filtering step
        for i in range(n):
            current_weight = np.sum(weight[i])
            if not is_feasible(prize[i], current_weight):
                heuristic[i] = 0
            else:
                heuristic[i] = prize[i]

        # Particle swarm optimization step
        update_swarm(swarm_positions, swarm_velocities, particle_best_positions, particle_best_scores)
        # Update global best position and score
        current_global_best_score = np.sum(global_best_position * prize)
        if current_global_best_score > global_best_score:
            global_best_score = current_global_best_score
            global_best_position = particle_best_positions

    # Calculate final heuristic based on PSO's global best
    heuristic = global_best_score

    return heuristic
```
