```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    m = weight.shape[1]
    heuristic = np.zeros((prize.shape[0],))
    
    # Deep reinforcement learning (DRL) model for real-time decision-making
    def drl_heuristic(i, weight):
        # Placeholder for the DRL model which will provide a heuristic
        # Here we use a simple random heuristic for demonstration purposes
        return np.random.rand()
    
    # Particle Swarm Optimization (PSO) for evolutionary swarm intelligence
    def pso_heuristic(i, prize, weight):
        # Placeholder for the PSO algorithm which will provide a heuristic
        # Here we use a simple random heuristic for demonstration purposes
        return np.random.rand()
    
    # Adaptive constraint-driven filtering for maintaining multi-dimensional feasibility
    def constraint_driven_filter(i, weight):
        return np.all(weight[:i+1].sum(axis=1) <= 1)
    
    for i in range(prize.shape[0]):
        if constraint_driven_filter(i, weight):
            drl_score = drl_heuristic(i, weight[i].reshape(1, m))
            pso_score = pso_heuristic(i, prize[i].reshape(1,), weight[i].reshape(1, m))
            heuristic[i] = drl_score + pso_score
    
    # Sparsify the heuristics by setting unpromising elements to zero
    # This step could be more sophisticated in a real-world scenario
    heuristic[heuristic < np.percentile(heuristic, 10)] = 0
    
    return heuristic
```
