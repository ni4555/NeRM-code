```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    m = weight.shape[1]
    heuristic = np.zeros((prize.shape[0],))
    
    # Deep Reinforcement Learning (DRL) component
    # Placeholder for DRL model, which would predict the heuristic values
    # For the sake of the example, we'll use a simple linear model
    drl_model = np.polyfit(np.arange(prize.shape[0]), prize, 1)
    heuristic = np.polyval(drl_model, np.arange(prize.shape[0]))
    
    # Particle Swarm Optimization (PSO) component
    # Placeholder for PSO algorithm, which would optimize the heuristic values
    # For the sake of the example, we'll use a simple random walk
    for i in range(prize.shape[0]):
        # Random walk to simulate PSO optimization
        heuristic[i] += np.random.normal(0, 0.1)
    
    # Adaptive Constraint-Driven Filtering component
    for i in range(prize.shape[0]):
        total_prize = 0
        total_weight = np.zeros(m)
        for j in range(i, prize.shape[0]):
            total_weight += weight[j]
            if np.any(total_weight > 1):
                break
            total_prize += prize[j]
        heuristic[i] = total_prize
    
    # Sparsify heuristics by setting values less than a threshold to zero
    threshold = np.percentile(heuristic, 25)
    heuristic[heuristic < threshold] = 0
    
    return heuristic
```
