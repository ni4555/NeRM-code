```python
def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    m = weight.shape[1]
    heuristic = np.zeros((prize.shape[0],))
    
    # Deep Reinforcement Learning component
    def deep_reinforcement_learning(prize, weight):
        # Placeholder for a deep reinforcement learning model
        # In practice, this would involve a neural network that predicts utility based on the state
        # For this heuristic, we will assume it returns a uniform utility for simplicity
        return np.ones_like(prize)
    
    # Adaptive constraint-driven filtering component
    def adaptive_constraint_filtering(prize, weight):
        heuristic_filter = np.zeros_like(prize)
        for i in range(prize.shape[0]):
            total_prize = 0
            total_weight = np.zeros(m)
            for j in range(i, prize.shape[0]):
                for k in range(m):
                    total_weight[k] += weight[j][k]
                    if total_weight[k] > 1:
                        break
                if np.any(total_weight > 1):
                    break
                total_prize += prize[j]
            heuristic_filter[i] = total_prize
        return heuristic_filter
    
    # Particle Swarm Optimization component
    def particle_swarm_optimization(prize, weight):
        # Placeholder for a particle swarm optimization algorithm
        # In practice, this would involve a swarm of particles moving in the search space
        # For this heuristic, we will assume it returns a random heuristic for simplicity
        return np.random.rand_like(prize)
    
    # Combine the components
    heuristic = (deep_reinforcement_learning(prize, weight) +
                 adaptive_constraint_filtering(prize, weight) +
                 particle_swarm_optimization(prize, weight)) / 3
    
    # Sparsify the heuristic
    heuristic[heuristic < np.percentile(heuristic, 95)] = 0
    
    return heuristic
```
