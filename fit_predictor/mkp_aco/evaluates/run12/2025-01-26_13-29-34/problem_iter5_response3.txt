```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]
    heuristic = np.zeros((n,))

    # Deep reinforcement learning component (simplified)
    model_scores = np.random.rand(n)

    # Initialize adaptive constraint-driven filtering
    constraint_violation = np.sum(weight, axis=1) > 1
    feasible_items = ~constraint_violation

    # Particle swarm optimization for evolutionary swarm intelligence
    # Simulating PSO by maintaining a particle's position and velocity
    # We use random initial positions for simplicity
    positions = np.random.rand(n, 1)
    velocities = np.random.rand(n, 1)
    inertia_weight = 0.5
    cognitive_weight = 1.5
    social_weight = 1.5

    for _ in range(50):  # Assuming 50 iterations for simplicity
        for i in range(n):
            # Update velocity
            velocities[i] = (inertia_weight * velocities[i] +
                             cognitive_weight * np.random.rand() * (positions[i] - model_scores[i]) +
                             social_weight * np.random.rand() * (positions[np.argmax(model_scores)] - model_scores[i]))

            # Update position
            positions[i] += velocities[i]

            # Constraint check
            if np.sum(weight[i]) > 1:
                positions[i] = model_scores[i]

        # Update heuristics based on PSO positions
        heuristic = positions

    # Combine RL and PSO scores
    heuristic = heuristic * model_scores

    # Apply adaptive constraint-driven filtering
    heuristic[constraint_violation] = 0

    # Normalize heuristics
    heuristic /= np.sum(heuristic)

    return heuristic
```
