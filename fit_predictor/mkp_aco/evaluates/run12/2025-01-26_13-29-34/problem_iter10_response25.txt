```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]
    heuristic = np.zeros((n,))

    # Deep reinforcement learning component (using a pre-trained model)
    model_scores = np.random.rand(n)  # Simulated pre-trained model scores

    # Adaptive constraint-driven filtering with sparsity
    feasible_items = np.ones(n, dtype=bool)
    for i in range(n):
        if np.any(weight[i, :] > 1):
            feasible_items[i] = False

    # Particle swarm optimization for evolutionary swarm intelligence
    # Initialize positions as the initial item indices
    positions = np.arange(n)
    velocities = np.random.rand(n)
    best_position = positions[np.argmax(model_scores)]
    best_score = model_scores[best_position]
    
    # PSO parameters
    inertia_weight = 0.7
    cognitive_coefficient = 1.5
    social_coefficient = 1.5
    max_velocity = 5  # Limit the velocities to avoid divergent movements

    for iteration in range(50):  # 50 iterations of PSO
        new_positions = positions + (inertia_weight * velocities +
                                    cognitive_coefficient * np.random.rand(n) * (positions - best_position) +
                                    social_coefficient * np.random.rand(n) * (positions - positions))
        
        # Apply velocity limits
        new_positions = np.clip(new_positions, 0, n - 1)
        velocities = new_positions - positions
        positions = new_positions
        
        # Evaluate new positions
        new_scores = model_scores[positions]
        new_best_position = positions[np.argmax(new_scores)]
        new_best_score = new_scores[new_best_position]
        
        # Update the global best if a better score is found
        if new_best_score > best_score:
            best_position = new_best_position
            best_score = new_best_score

    global_best_index = best_position

    # Heuristic scaling based on model scores, prize value, and feasibility
    for i in range(n):
        if not feasible_items[i]:
            heuristic[i] = 0
        else:
            score = model_scores[i] * (prize[i] / (prize[global_best_index] + 1e-6))

    # Adaptive learning mechanism
    # Adjust the heuristic for less promising items based on their score
    for i in range(n):
        if heuristic[i] < best_score * 0.5:
            heuristic[i] *= 0.9

    # Normalize the heuristic to ensure all values are within a reasonable range
    heuristic /= np.max(heuristic)

    return heuristic
```
