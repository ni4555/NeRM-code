```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    heuristic = np.zeros((n,))

    # Deep reinforcement learning for real-time decision-making
    rl_model = np.random.rand(n)
    for _ in range(1000):
        for i in range(n):
            action = np.random.choice([0, 1], p=[1 - rl_model[i], rl_model[i]])
            if action == 1:
                if np.any(weight[i] > 1):
                    rl_model[i] *= (1 - 0.1)  # Decrease the probability if not feasible
                else:
                    heuristic[i] = np.sum(prize[i])
            else:
                heuristic[i] = 0

    # Adaptive constraint-driven filtering to maintain multi-dimensional feasibility
    for _ in range(1000):
        for i in range(n):
            if np.any(weight[i] > 1):
                heuristic[i] = 0
            else:
                heuristic[i] *= (1 - 0.1)  # Gradually reduce the heuristic value if feasible

    # Particle swarm optimization for evolutionary swarm intelligence
    particles = np.random.rand(n, n)
    velocities = np.random.rand(n, n)
    best_positions = particles.copy()
    best_fitness = heuristic.copy()

    for _ in range(100):
        for i in range(n):
            velocities[i] = 0.5 * velocities[i] + 0.1 * (best_positions[i] - particles[i])
            particles[i] += velocities[i]
            if heuristic[i] > best_fitness[i]:
                best_positions[i] = particles[i]
                best_fitness[i] = heuristic[i]

    heuristic = best_fitness

    return heuristic
```
