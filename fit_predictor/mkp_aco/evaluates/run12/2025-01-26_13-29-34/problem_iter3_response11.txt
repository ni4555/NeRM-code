```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    m = weight.shape[1]
    heuristic = np.zeros((prize.shape[0],))
    
    # Deep Reinforcement Learning (DRL) component
    # Here we assume a hypothetical function `get_rl_value` that takes item index and returns a value
    # This function is not defined here as it would require a full DRL model
    for i in range(prize.shape[0]):
        rl_value = get_rl_value(i)
        
        # Particle Swarm Optimization (PSO) component
        # We assume a hypothetical function `get_pso_value` that takes item index and returns a value
        # This function is not defined here as it would require a full PSO model
        pso_value = get_pso_value(i)
        
        # Domain-specific heuristic
        total_prize = 0
        total_weight = 0
        for j in range(i, prize.shape[0]):
            for k in range(m):
                total_weight += weight[j][k]
            if total_weight > 1:
                break
            total_prize += prize[j]
        
        # Adaptive constraint-driven filtering
        if total_weight <= 1:
            heuristic[i] = rl_value + pso_value + total_prize
        else:
            heuristic[i] = 0  # Unpromising if constraint is violated
    
    # Sparsify heuristics by setting unpromising elements to zero
    heuristic[heuristic < np.percentile(heuristic, 5)] = 0
    
    return heuristic
```
