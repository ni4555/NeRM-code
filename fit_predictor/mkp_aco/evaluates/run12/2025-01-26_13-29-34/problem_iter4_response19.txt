```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]
    heuristic = np.zeros((n,))

    # Deep reinforcement learning for real-time decision-making
    # Assuming a pre-trained model that outputs a continuous value representing item importance
    rl_model = np.random.rand(n)  # Simulating a model output

    # Adaptive constraint-driven filtering
    # Maintain a running total weight and ensure it doesn't exceed the capacity
    running_total_weight = np.zeros(n)
    max_capacity = np.ones(n)

    # Particle swarm optimization for evolutionary swarm intelligence
    # Initialize swarm
    particles = np.random.rand(n, n)
    velocities = np.random.rand(n, n)
    local_best_positions = particles.copy()
    local_best_scores = heuristic.copy()
    global_best_score = -np.inf
    global_best_position = None

    # Define a fitness function
    def fitness(position):
        score = np.sum(prize[position]) - np.sum(weight[position])
        return score

    # Main loop for the heuristics
    for iteration in range(100):
        # Update velocities and particles
        velocities = 0.5 * velocities + np.random.rand(n, n) * 0.2
        particles += velocities

        # Update local bests
        for i in range(n):
            local_score = fitness(particles[i])
            if local_score > local_best_scores[i]:
                local_best_scores[i] = local_score
                local_best_positions[i] = particles[i]

        # Update global best
        global_best_score = np.max(local_best_scores)
        global_best_position = np.argmax(local_best_scores)

        # Update running total weights and apply adaptive filtering
        running_total_weight += weight[global_best_position]
        if running_total_weight > max_capacity:
            heuristic = np.zeros(n)
            return heuristic  # Reset heuristics if infeasible

        # Update heuristics based on reinforcement learning and swarm intelligence
        heuristic = rl_model * fitness(global_best_position) / global_best_score

    return heuristic
```
