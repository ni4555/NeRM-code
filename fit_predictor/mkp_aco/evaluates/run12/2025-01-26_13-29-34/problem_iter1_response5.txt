```python
def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n, m = prize.shape
    heuristic = np.zeros((n,))

    # Deep reinforcement learning model for real-time decision-making
    # Here we simulate the decision-making process with a random policy
    policy = np.random.rand(n, 2)  # 2 represents the action space: include or exclude
    policy = np.argmax(policy, axis=1)

    # Adaptive constraint-driven filtering for maintaining multi-dimensional feasibility
    for i in range(n):
        if policy[i] == 1:  # If the item is included
            total_weight = weight[i].sum()
            if total_weight > 1:
                policy[i] = 0  # Set the item as not included due to constraint violation

    # Particle swarm optimization for evolutionary swarm intelligence
    # Here we simulate the particle swarm optimization process with random positions
    pso_position = np.random.rand(n)
    pso_velocity = np.random.rand(n)
    w = 0.5  # Inertia weight
    c1 = 1.5  # Cognitive coefficient
    c2 = 1.5  # Social coefficient

    for _ in range(50):  # Number of iterations, can be adjusted
        for i in range(n):
            pso_velocity[i] = w * pso_velocity[i] + c1 * np.random.rand() * (prize[i] - pso_position[i]) + c2 * np.random.rand() * (prize[policy[i]] - pso_position[i])
            pso_position[i] += pso_velocity[i]
            if pso_position[i] > 1:
                pso_position[i] = 1
            if pso_position[i] < 0:
                pso_position[i] = 0

    # Combine various factors to determine the heuristics
    heuristic = (prize * (1 - pso_position)) + (prize[policy] * pso_position)

    # Sparsify the heuristics by setting unpromising elements to zero
    heuristic[heuristic < heuristic.max() * 0.1] = 0

    return heuristic
```
