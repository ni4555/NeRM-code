```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    m = weight.shape[1]
    heuristic = np.zeros((prize.shape[0],))

    # Deep Reinforcement Learning for real-time decision-making
    rl_heuristic = _deep_reinforcement_learning(prize, weight)

    # Particle Swarm Optimization for evolutionary swarm intelligence
    pso_heuristic = _particle_swarm_optimization(prize, weight)

    # Adaptive constraint-driven filtering for maintaining multi-dimensional feasibility
    feasibility_filter = _adaptive_constraint_filtering(prize, weight)

    # Combine heuristics
    for i in range(prize.shape[0]):
        heuristic[i] = rl_heuristic[i] + pso_heuristic[i] + feasibility_filter[i]

        # Sparsify the heuristics
        if heuristic[i] < 1e-5:
            heuristic[i] = 0

    return heuristic

def _deep_reinforcement_learning(prize, weight):
    # Placeholder for RL-based heuristic calculation
    return np.random.rand(prize.shape[0])

def _particle_swarm_optimization(prize, weight):
    # Placeholder for PSO-based heuristic calculation
    return np.random.rand(prize.shape[0])

def _adaptive_constraint_filtering(prize, weight):
    # Placeholder for constraint-driven filtering
    return np.ones(prize.shape[0])  # Assuming all items are feasible initially

# Note: The placeholders `_deep_reinforcement_learning`, `_particle_swarm_optimization`, and `_adaptive_constraint_filtering`
# should be replaced with actual implementations that fit the specific problem and desired level of complexity.
```
