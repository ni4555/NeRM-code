```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Calculate value-to-weight ratio for each item
    value_to_weight_ratio = prize / weight.sum(axis=1)
    
    # Normalize the value-to-weight ratio to ensure non-negative values
    min_ratio = np.min(value_to_weight_ratio)
    if min_ratio <= 0:
        value_to_weight_ratio = -value_to_weight_ratio + 1
    
    # Calculate a penalty factor for outliers based on the percentile of the ratio
    penalty_factor = np.abs(value_to_weight_ratio - np.percentile(value_to_weight_ratio, 75))
    
    # Normalize the penalty factor
    max_penalty = np.max(penalty_factor)
    penalty_factor = penalty_factor / max_penalty
    
    # Calculate a density factor based on the ratio
    density_factor = value_to_weight_ratio / np.mean(value_to_weight_ratio)
    
    # Combine the normalized ratio with the penalty and density factors
    combined_heuristics = value_to_weight_ratio * (1 - penalty_factor + density_factor)
    
    # Introduce a balance factor that promotes diversity and prevents premature convergence
    balance_factor = 1 / (1 + np.exp(-combined_heuristics))
    
    # Sparsify the heuristics to promote diversity
    sparsity_threshold = np.percentile(combined_heuristics * balance_factor, 25)
    sparsified_heuristics = np.where(combined_heuristics * balance_factor > sparsity_threshold, combined_heuristics * balance_factor, 0)
    
    # Introduce randomness to maintain heuristic diversity and explore new regions
    np.random.seed(0)  # Ensure reproducibility
    random_noise = np.random.normal(0, 0.1, size=sparsified_heuristics.shape)
    final_heuristics = sparsified_heuristics + random_noise
    
    # Normalize the heuristic to ensure it is between 0 and 1
    final_heuristics = (final_heuristics - np.min(final_heuristics)) / (np.max(final_heuristics) - np.min(final_heuristics))
    
    return final_heuristics
```
