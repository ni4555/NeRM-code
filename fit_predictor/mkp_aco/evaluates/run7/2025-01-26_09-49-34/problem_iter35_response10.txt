```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Calculate the initial heuristics based on the product of normalized prize, sparsity factor, and inverse variance factor
    heuristics = normalized_prize * sparsity_factor * inv_variance_factor
    
    # Introduce diversity by adding a random perturbation to heuristics
    np.random.seed(1)  # Ensure reproducibility
    perturbation = np.random.normal(0, 0.01, size=heuristics.shape)
    heuristics += perturbation
    
    # Adjust heuristics based on a dynamic threshold that considers the current distribution
    threshold = np.percentile(heuristics, 60)  # 60% threshold for balancing
    heuristics[heuristics < threshold] *= 1.2  # Increase heuristics below threshold
    heuristics[heuristics > threshold] *= 0.8  # Decrease heuristics above threshold
    
    # Introduce sparsity by setting heuristics below a certain percentile to zero
    lower_threshold = np.percentile(heuristics, 10)  # 10% threshold for sparsity
    heuristics[heuristics < lower_threshold] = 0
    
    # Refine heuristics iteratively by balancing exploration and exploitation
    # Promote items that are above the threshold and have good sparsity
    for i in range(len(heuristics)):
        if heuristics[i] > threshold and sparsity_factor[i] > 0.5:
            heuristics[i] *= 1.2
    
    # Normalize heuristics by dividing by the sum of heuristics to avoid division by zero
    heuristic_sum = np.sum(heuristics)
    if heuristic_sum > 0:
        heuristics /= heuristic_sum
    
    return heuristics
```
