```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Calculate the diversity factor based on the number of unique weight dimensions
    diversity_factor = np.count_nonzero(weight == 0, axis=1) / (weight.shape[1] - np.count_nonzero(weight == 0, axis=1))
    
    # Introduce randomness with a perturbation to encourage exploration
    np.random.seed(0)  # Ensure reproducibility
    perturbation = np.random.normal(0, 0.02, size=heuristics.shape)
    heuristics = normalized_prize * sparsity_factor * inv_variance_factor * diversity_factor + perturbation
    
    # Adapt thresholds based on the current distribution of heuristics
    thresholds = np.percentile(heuristics, [20, 50, 70, 90])
    lower_threshold, median_threshold, high_threshold, upper_threshold = thresholds
    
    # Apply heuristics refinement
    heuristics[heuristics < lower_threshold] = 0
    heuristics[heuristics > upper_threshold] = 0
    
    # Introduce sparsity by adjusting heuristics based on the median threshold
    heuristics[heuristics < median_threshold] *= 0.8
    heuristics[heuristics >= median_threshold] *= 1.2
    
    # Refine heuristics iteratively by balancing exploration and exploitation
    for i in range(len(heuristics)):
        if heuristics[i] >= median_threshold and sparsity_factor[i] > 0.5:
            heuristics[i] *= 1.1
    
    # Normalize heuristics by dividing by the sum of heuristics to avoid division by zero
    heuristic_sum = np.sum(heuristics)
    if heuristic_sum > 0:
        heuristics /= heuristic_sum
    
    return heuristics
```
