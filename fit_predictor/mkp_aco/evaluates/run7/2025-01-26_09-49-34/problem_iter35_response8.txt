```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Calculate the initial heuristics based on the product of normalized prize and sparsity factor
    heuristics = normalized_prize * sparsity_factor * inv_variance_factor
    
    # Introduce noise to heuristics to ensure diversity
    np.random.seed(0)  # Ensure reproducibility
    noise = np.random.normal(0, 0.01, size=heuristics.shape)
    heuristics += noise
    
    # Use a dynamic threshold that adapts to the current distribution of heuristics
    threshold = np.percentile(heuristics, 70)  # 70% threshold for aggressive adjustment
    
    # Adjust heuristics based on a balance between the current heuristics and the threshold
    adjusted_heuristics = np.clip(heuristics + noise, 0, threshold)
    
    # Refine heuristics iteratively by balancing exploration and exploitation
    # Increase heuristics for items that are promising and not too sparse
    for i in range(len(heuristics)):
        if adjusted_heuristics[i] > threshold and sparsity_factor[i] > 0.5:
            adjusted_heuristics[i] *= 1.2
    
    # Introduce sparsity by setting less promising heuristics to zero
    lower_threshold = np.percentile(adjusted_heuristics, 20)  # 20% threshold for sparsity
    adjusted_heuristics[adjusted_heuristics < lower_threshold] = 0
    
    # Normalize heuristics by dividing by the sum of heuristics to avoid division by zero
    heuristic_sum = np.sum(adjusted_heuristics)
    if heuristic_sum > 0:
        adjusted_heuristics /= heuristic_sum
    
    return adjusted_heuristics
```
