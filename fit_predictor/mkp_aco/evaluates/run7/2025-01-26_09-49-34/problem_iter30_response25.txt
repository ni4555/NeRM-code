```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize to encourage balance between all items
    normalized_prize = prize / np.sum(prize)
    
    # Sparsity factor encourages items with fewer non-zero dimensions
    sparsity_factor = np.count_nonzero(weight, axis=1) / weight.shape[1]
    
    # Inverse variance factor encourages items with lower variance in weight
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Combine factors using a weighted approach
    # Higher weight given to normalized prize as it directly relates to the objective
    combined_factor = normalized_prize * 0.8 * sparsity_factor * inv_variance_factor * 0.2
    
    # Apply a dynamic threshold to balance exploration and exploitation
    # Increase heuristics for items closer to the threshold
    threshold = np.percentile(combined_factor, 80)  # 80% threshold for adjustment
    heuristics = combined_factor * np.where(combined_factor > threshold, 1.5, 1)
    
    # Normalize heuristics to scale the results
    max_heuristic = np.max(heuristics)
    if max_heuristic > 0:
        heuristics /= max_heuristic
    
    # Sparsify the heuristics to avoid overfitting and encourage diversity
    num_to_zero = int(len(heuristics) * 0.1)  # Zero out 10% of the lowest heuristics
    heuristics[np.argsort(heuristics)[:num_to_zero]] = 0
    
    # Apply noise to enhance the search space
    noise_factor = np.random.rand(*heuristics.shape) * 0.1
    heuristics += noise_factor
    
    # Iterate to refine heuristics
    for _ in range(2):  # Iterate to refine heuristics further
        # Reduce heuristics for the bottom half that are below the median
        median_heuristic = np.median(heuristics)
        heuristics[heuristics < median_heuristic] *= 0.9
    
    return heuristics
```
