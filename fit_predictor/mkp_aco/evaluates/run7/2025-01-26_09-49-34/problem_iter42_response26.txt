```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]

    # Normalize prize to ensure fairness in comparison
    normalized_prize = prize / np.max(prize)
    
    # Calculate sparsity factor
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Combine factors into a heuristic value
    heuristic_value = normalized_prize * sparsity_factor * inv_variance_factor
    
    # Introduce a diversity factor with a small random perturbation
    diversity_factor = np.random.normal(0, 0.01, size=n)
    
    # Apply diversity factor
    heuristic_value += diversity_factor
    
    # Dynamic thresholding based on the interquartile range (IQR) of the heuristic values
    quartiles = np.percentile(heuristic_value, [25, 75])
    iqr = quartiles[1] - quartiles[0]
    threshold = quartiles[0] + 1.5 * iqr
    
    # Refine heuristics using the threshold
    heuristic_value[heuristic_value < threshold] = 0
    
    # Iteratively refine heuristics
    for _ in range(3):
        # Amplify non-dominated heuristics
        for i in range(n):
            if heuristic_value[i] > 0:
                dominated_by = np.any(heuristic_value > heuristic_value[i])
                if not dominated_by:
                    heuristic_value[i] *= 1.05
        
        # Re-introduce sparsity by zeroing out low-value heuristics
        heuristic_value[heuristic_value < threshold] = 0
        
        # Adjust the threshold for the next iteration based on the current heuristics
        quartiles = np.percentile(heuristic_value, [25, 75])
        iqr = quartiles[1] - quartiles[0]
        threshold = quartiles[0] + 1.5 * iqr
    
    # Normalize the final heuristics
    heuristic_sum = np.sum(heuristic_value)
    if heuristic_sum > 0:
        heuristic_value /= heuristic_sum
    
    return heuristic_value
```
