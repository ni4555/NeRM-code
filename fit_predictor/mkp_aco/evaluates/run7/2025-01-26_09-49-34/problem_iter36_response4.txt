```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Calculate the diversity factor
    diversity_factor = np.exp(-np.sum(weight ** 2, axis=1))
    
    # Combine factors using a weighted approach, giving more weight to normalized prize and sparsity
    combined_factor = normalized_prize * 0.7 * sparsity_factor * inv_variance_factor * diversity_factor
    
    # Introduce random noise to promote diversity
    noise_factor = np.random.rand(*combined_factor.shape) * 0.05
    
    # Adjust heuristics based on the weighted combination of factors and noise
    heuristics = combined_factor + noise_factor
    
    # Apply adaptive thresholding to encourage exploration
    threshold = np.percentile(heuristics, 50)  # 50% threshold for exploration
    heuristics[heuristics > threshold] *= 1.5
    
    # Refine heuristics iteratively to ensure robustness
    for _ in range(2):  # Iteratively refine heuristics
        heuristics[heuristics < threshold] *= 0.8  # Reduce lower heuristics
    
    # Incorporate domain knowledge: favor items with higher diversity and lower variance
    heuristics *= diversity_factor
    
    # Normalize heuristics by dividing by the sum of heuristics to avoid division by zero
    heuristic_sum = np.sum(heuristics)
    if heuristic_sum > 0:
        heuristics /= heuristic_sum
    
    # Sparsify the heuristics by setting a fraction of the lowest heuristics to zero
    num_to_zero = int(len(heuristics) * 0.05)  # Zero out 5% of the lowest heuristics
    heuristics[np.argsort(heuristics)[:num_to_zero]] = 0
    
    return heuristics
```
