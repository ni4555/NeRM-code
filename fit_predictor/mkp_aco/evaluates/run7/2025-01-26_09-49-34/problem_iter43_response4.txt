```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]
    
    # Normalize prize using min-max scaling to avoid dominance by high prizes
    min_prize = np.min(prize)
    max_prize = np.max(prize)
    normalized_prize = (prize - min_prize) / (max_prize - min_prize)
    
    # Calculate a diversity factor that emphasizes non-dominated items
    diversity_factor = np.random.normal(0, 0.02, size=normalized_prize.shape)
    diversity_factor = np.maximum(diversity_factor, 0)
    
    # Use a threshold-based selection that emphasizes items with high normalized prize
    threshold = np.percentile(normalized_prize, 70)
    threshold_factor = np.where(normalized_prize > threshold, normalized_prize, 0)
    
    # Calculate the balance factor using variance and sparsity
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    balance_factor = sparsity_factor * inv_variance_factor
    
    # Combine factors to create the initial heuristics
    heuristics = normalized_prize * balance_factor + diversity_factor * threshold_factor
    
    # Apply controlled noise to introduce diversity
    noise = np.random.normal(0, 0.01, size=heuristics.shape)
    heuristics += noise
    
    # Iteratively refine the heuristics
    for i in range(n):
        # Amplify heuristics for items that are not dominated and have high sparsity
        if heuristics[i] > 0 and sparsity_factor[i] > 0.5:
            heuristics[i] *= 1.1
    
    # Sparsify by setting low heuristics to zero
    sparsity_threshold = np.percentile(heuristics, 30)
    heuristics[heuristics < sparsity_threshold] = 0
    
    # Normalize the heuristics to maintain balance
    heuristics /= np.sum(heuristics)
    
    return heuristics
```
