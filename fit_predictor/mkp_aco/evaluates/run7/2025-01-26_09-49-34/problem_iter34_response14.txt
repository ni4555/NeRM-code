```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n, m = prize.shape[0], weight.shape[1]
    
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Integrate domain knowledge: Consider items with a higher ratio of prize to weight as more promising
    ratio_factor = normalized_prize / weight.sum(axis=1)
    
    # Introduce sparsity factor based on the sum of weights to avoid overfitting to dense items
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Introduce variance factor to promote diversity and robustness
    variance_factor = np.mean(weight ** 2, axis=1) / np.mean(weight, axis=1)
    
    # Calculate heuristic based on a combination of factors
    heuristics = normalized_prize * ratio_factor * sparsity_factor * variance_factor
    
    # Control noise levels to promote diversity and avoid premature convergence
    noise_level = np.random.rand() / np.sum(sparsity_factor)
    perturbation = np.random.normal(0, noise_level, size=heuristics.shape)
    heuristics += perturbation
    
    # Introduce dynamic thresholding with adaptive weight to maintain diversity
    threshold_weight = np.random.rand()
    threshold = np.percentile(heuristics, (1 - threshold_weight) * 100)
    heuristics[heuristics < threshold] = 0
    
    # Refine thresholds iteratively based on the sparsity factor
    items_to_refine = heuristics > 0
    for i in range(len(heuristics)):
        if not items_to_refine[i] and sparsity_factor[i] > 0.5:
            heuristics[i] = threshold
    
    # Normalize heuristics to ensure they sum to 1
    heuristic_sum = np.sum(heuristics)
    if heuristic_sum > 0:
        heuristics /= heuristic_sum
    
    # Adapt sparsity based on performance to improve the heuristic's accuracy
    performance_factor = np.mean(prize[heuristics > 0]) / np.mean(prize)
    heuristics *= performance_factor
    
    return heuristics
```
