```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Sparsity factor for items with zero weight in all dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Inverse variance factor to account for variability in weights
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Factor to balance the importance of high prize and low variance
    balance_factor = normalized_prize * sparsity_factor * inv_variance_factor
    
    # Determine dynamic thresholds based on the distribution of the balance factors
    amplification_threshold = np.percentile(balance_factor, 70)
    reduction_threshold = np.percentile(balance_factor, 30)
    
    # Amplify higher potential items and reduce lower potential items
    heuristics = balance_factor
    heuristics[heuristics > amplification_threshold] *= 1.5
    heuristics[heuristics < reduction_threshold] *= 0.5
    
    # Add noise to promote diversity, scaled by the standard deviation of the balance factors
    noise_level = np.std(balance_factor)
    perturbation = np.random.normal(0, noise_level, size=balance_factor.shape)
    heuristics += perturbation
    
    # Dynamic thresholding with an adaptive weight based on the median heuristic value
    median_heuristic = np.median(heuristics)
    threshold = median_heuristic * (1 - np.random.rand())
    
    # Set heuristics below the threshold to zero to promote sparsity
    heuristics[heuristics < threshold] = 0
    
    # Refine heuristics by promoting those that are above the threshold and are sparse
    items_to_keep = (heuristics > 0) & (sparsity_factor > 0.5)
    heuristics[~items_to_keep] = 0
    
    # Normalize heuristics to ensure they sum to 1
    heuristic_sum = np.sum(heuristics)
    if heuristic_sum > 0:
        heuristics /= heuristic_sum
    
    return heuristics
```
