```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n, m = prize.shape[0], weight.shape[1]

    # Normalize prize to avoid dominance
    normalized_prize = prize / np.max(prize)

    # Calculate sparsity factor
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)

    # Calculate inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)

    # Combine factors for balance
    balance_factor = sparsity_factor * inv_variance_factor

    # Add controlled diversity with noise
    diversity = np.random.normal(0, 0.02, size=normalized_prize.shape)
    diversity = np.maximum(diversity, 0)
    combined_factor = normalized_prize * balance_factor + diversity

    # Dynamically adjust thresholds
    threshold = np.percentile(combined_factor, 50)  # Median heuristic value as threshold
    combined_factor[combined_factor < threshold] = 0

    # Amplify heuristics of items with higher potential
    amplification_threshold = np.percentile(combined_factor, 70)
    combined_factor[combined_factor > amplification_threshold] *= 1.2

    # Emphasize non-dominated items
    for i in range(combined_factor.shape[0]):
        dominated_by = np.any(combined_factor > combined_factor[i])
        if not dominated_by:
            combined_factor[i] *= 1.1

    # Refine heuristics through iterations
    for _ in range(2):
        for i in range(combined_factor.shape[0]):
            dominated_by = np.any(combined_factor > combined_factor[i])
            if not dominated_by:
                combined_factor[i] *= 1.05

    # Normalize the final heuristics
    heuristic_sum = np.sum(combined_factor)
    if heuristic_sum > 0:
        combined_factor /= heuristic_sum

    return combined_factor
```
