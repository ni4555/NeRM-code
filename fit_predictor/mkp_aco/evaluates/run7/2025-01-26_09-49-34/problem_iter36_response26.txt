```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Introduce randomness for diversity
    random_factor = np.random.rand(*normalized_prize.shape) * 0.1
    
    # Combine factors using a weighted approach
    combined_factor = normalized_prize * 0.6 * sparsity_factor * inv_variance_factor * 0.4 + random_factor
    
    # Apply adaptive thresholding for exploration
    median_heuristic = np.median(combined_factor)
    combined_factor[combined_factor < median_heuristic] *= 0.8
    
    # Refine iteratively for robustness
    for _ in range(3):  # Refine heuristics iteratively
        median_heuristic = np.median(combined_factor)
        combined_factor[combined_factor > median_heuristic] *= 1.1
    
    # Incorporate domain knowledge: favor items with higher diversity and lower variance
    diversity_factor = np.exp(-np.sum(weight ** 2, axis=1))
    combined_factor *= diversity_factor
    
    # Normalize heuristics by dividing by the maximum heuristic value
    max_heuristic = np.max(combined_factor)
    if max_heuristic > 0:
        combined_factor /= max_heuristic
    
    # Sparsify the heuristics by setting a fraction of the lowest heuristics to zero
    num_to_zero = int(len(combined_factor) * 0.1)  # Zero out 10% of the lowest heuristics
    combined_factor[np.argsort(combined_factor)[:num_to_zero]] = 0
    
    return combined_factor
```
