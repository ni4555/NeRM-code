```python
def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Initialize heuristics with a default value
    heuristics = np.ones_like(prize)
    
    # Normalize prize to avoid dominance by high values
    normalized_prize = prize / np.max(prize)
    
    # Iteratively adjust heuristics
    for _ in range(10):
        # Promote items based on their prize value
        heuristics *= normalized_prize
        
        # Add a random exploration factor to encourage diversity
        exploration_factor = np.random.normal(0, 0.05, size=normalized_prize.shape)
        heuristics += exploration_factor
        
        # Adjust heuristics based on sparsity to avoid over-reliance on a few items
        sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
        heuristics *= sparsity_factor
        
        # Introduce a penalty for items that do not contribute to the diversity of weight
        diversity_penalty = np.mean(weight, axis=1) / np.std(weight, axis=1)
        heuristics -= diversity_penalty
        
        # Limit the heuristics to ensure they do not dominate each other
        heuristics = np.clip(heuristics, 0, 1)
        
    # Amplify heuristics of items that have a good balance of prize and diversity
    balance_factor = normalized_prize * sparsity_factor
    heuristics *= balance_factor
    
    return heuristics
```
