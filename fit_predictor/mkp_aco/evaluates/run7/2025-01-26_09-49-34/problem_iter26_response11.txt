```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Calculate the initial heuristics based on the product of normalized prize and sparsity factor
    heuristics = normalized_prize * sparsity_factor * inv_variance_factor
    
    # Use dynamic thresholds for adaptive weighting
    # Define a threshold based on the 70th percentile of the sparsity_factor
    sparsity_threshold = np.percentile(sparsity_factor, 70)
    # Define a threshold based on the 70th percentile of the inv_variance_factor
    inv_variance_threshold = np.percentile(inv_variance_factor, 70)
    
    # Increase heuristics for items with sparsity and variance factors above their respective thresholds
    heuristics[sparsity_factor > sparsity_threshold] *= 1.2
    heuristics[inv_variance_factor > inv_variance_threshold] *= 1.2
    
    # Normalize heuristics by dividing by the maximum heuristic value
    max_heuristic = np.max(heuristics)
    if max_heuristic > 0:
        heuristics /= max_heuristic
    
    # Apply a dynamic sparsification strategy
    # Calculate the sparsity threshold for the heuristics
    heuristics_sparsity_threshold = np.percentile(heuristics, 70)
    # Set a fraction of the lowest heuristics to zero based on the sparsity threshold
    num_to_zero = int(len(heuristics) * 0.1)
    heuristics[np.argsort(heuristics)[:num_to_zero]] = 0
    
    return heuristics
```
