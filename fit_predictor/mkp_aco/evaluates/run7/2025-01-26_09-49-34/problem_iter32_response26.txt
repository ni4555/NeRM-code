```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize to a range [0, 1]
    normalized_prize = (prize - np.min(prize)) / (np.max(prize) - np.min(prize))
    
    # Calculate sparsity based on the number of non-zero weight dimensions
    sparsity = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the variance of weights for each item
    variance = np.var(weight, axis=1)
    
    # Calculate the diversity factor based on how unique the weight vector is
    diversity = np.exp(-np.sum(weight ** 2, axis=1))
    
    # Calculate the initial heuristics based on the product of normalized prize and sparsity
    initial_heuristics = normalized_prize * sparsity
    
    # Adjust heuristics based on the inverse of variance (to favor items with lower variance)
    adjusted_variance = 1 / (1 + variance)
    
    # Include diversity in heuristics to ensure a mix of items
    adjusted_diversity = diversity
    
    # Combine the factors into heuristics
    heuristics = initial_heuristics * adjusted_variance * adjusted_diversity
    
    # Refine thresholds and dynamically adjust weights based on performance
    # Sort heuristics and keep the top 30% to adjust their weight
    sorted_indices = np.argsort(heuristics)[::-1]
    top_items = sorted_indices[:int(len(heuristics) * 0.3)]
    heuristics[top_items] *= 1.5
    
    # Introduce a dynamic threshold to balance exploration and exploitation
    mean_heuristics = np.mean(heuristics)
    std_dev = np.std(heuristics)
    threshold = mean_heuristics + std_dev
    
    # Normalize heuristics to ensure they sum to 1, but maintain high values above the threshold
    heuristics[heuristics > threshold] = 1
    heuristics /= np.sum(heuristics)
    
    # Simplify the heuristics by setting a fraction of the lowest heuristics to zero
    num_to_zero = int(len(heuristics) * 0.1)
    heuristics[np.argsort(heuristics)[:num_to_zero]] = 0
    
    return heuristics
```
