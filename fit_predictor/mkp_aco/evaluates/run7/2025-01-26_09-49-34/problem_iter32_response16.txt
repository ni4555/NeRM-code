```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the inverse variance factor using normalized weights
    inv_variance_factor = np.mean(weight / np.sum(weight), axis=1) / np.mean((weight / np.sum(weight)) ** 2, axis=1)
    
    # Calculate the diversity factor using the entropy of the normalized weights
    diversity_factor = -np.sum((weight / np.sum(weight)) * np.log(weight / np.sum(weight)), axis=1)
    
    # Calculate the initial heuristics based on the weighted sum of factors
    # Weigh each factor according to its importance for the problem
    heuristics = (normalized_prize * 0.5 + sparsity_factor * 0.2 + inv_variance_factor * 0.2 + diversity_factor * 0.1)
    
    # Define adaptive weighting thresholds using percentiles
    sparsity_threshold = np.percentile(sparsity_factor, 75)
    inv_variance_threshold = np.percentile(inv_variance_factor, 75)
    diversity_threshold = np.percentile(diversity_factor, 75)
    
    # Apply adaptive weighting based on thresholds
    heuristics[sparsity_factor > sparsity_threshold] *= 1.1
    heuristics[inv_variance_factor > inv_variance_threshold] *= 1.1
    heuristics[diversity_factor > diversity_threshold] *= 1.1
    
    # Normalize heuristics by dividing by the sum of heuristics to maintain a total of 1
    heuristics /= np.sum(heuristics)
    
    # Apply sparsification by setting a fraction of the lowest heuristics to zero
    num_to_zero = int(len(heuristics) * 0.05)
    heuristics[np.argsort(heuristics)[:num_to_zero]] = 0
    
    return heuristics
```
