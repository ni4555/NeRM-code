```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]
    
    # Normalize prize to avoid dominance by high values
    normalized_prize = prize / np.max(prize)
    
    # Calculate sparsity factor for non-zero weight items
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate inverse variance to account for variability in weights
    inv_variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Combine the factors to create an initial heuristic
    initial_heuristic = normalized_prize * sparsity_factor * inv_variance_factor
    
    # Add a random component to encourage diversity
    random_factor = np.random.normal(0, 0.05, size=initial_heuristic.shape)
    initial_heuristic += random_factor
    
    # Apply a dynamic threshold based on the median heuristic
    median_heuristic = np.median(initial_heuristic)
    dynamic_threshold = median_heuristic * 0.75  # 75% threshold
    
    # Amplify heuristics above the dynamic threshold
    initial_heuristic[initial_heuristic > dynamic_threshold] *= 1.2
    
    # Apply sparsity by zeroing out heuristics below a percentile threshold
    sparsity_threshold = np.percentile(initial_heuristic, 20)  # 20% threshold
    initial_heuristic[initial_heuristic < sparsity_threshold] = 0
    
    # Refine heuristics iteratively
    for _ in range(3):  # Iterate 3 times
        for i in range(n):
            # Amplify heuristics that are not dominated by others
            if not np.any(initial_heuristic > initial_heuristic[i]):
                initial_heuristic[i] *= 1.1
    
    # Normalize the final heuristics to sum to 1
    heuristic_sum = np.sum(initial_heuristic)
    if heuristic_sum > 0:
        initial_heuristic /= heuristic_sum
    
    return initial_heuristic
```
