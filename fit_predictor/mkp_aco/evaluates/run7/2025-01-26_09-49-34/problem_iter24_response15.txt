```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    # Normalize prize by dividing each prize value by the sum of all prizes
    normalized_prize = prize / np.sum(prize)
    
    # Calculate the sparsity factor based on the number of non-zero weight dimensions
    sparsity_factor = (weight.sum(axis=1) > 0).astype(float)
    
    # Calculate the variance factor
    variance_factor = np.mean(weight, axis=1) / np.mean(weight ** 2, axis=1)
    
    # Combine sparsity and variance factors into a single heuristic
    combined_factor = sparsity_factor * variance_factor
    
    # Adjust combined factor to give preference to items with lower variance
    adjusted_combined_factor = 1 / (1 + combined_factor)
    
    # Normalize the combined factor by dividing by the maximum value
    max_combined_factor = np.max(adjusted_combined_factor)
    if max_combined_factor > 0:
        adjusted_combined_factor /= max_combined_factor
    
    # Apply a dynamic threshold to balance exploration and exploitation
    # Increase heuristics for items closer to the threshold
    threshold = np.percentile(adjusted_combined_factor, 70)  # 70% threshold
    adjusted_combined_factor[adjusted_combined_factor > threshold] *= 1.5
    
    # Normalize the heuristics by dividing by the maximum heuristic value
    max_heuristic = np.max(adjusted_combined_factor)
    if max_heuristic > 0:
        adjusted_combined_factor /= max_heuristic
    
    # Sparsify the heuristics by setting a fraction of the lowest heuristics to zero
    num_to_zero = int(len(adjusted_combined_factor) * 0.1)  # Zero out 10% of the lowest heuristics
    adjusted_combined_factor[np.argsort(adjusted_combined_factor)[:num_to_zero]] = 0
    
    return adjusted_combined_factor
```
