```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    
    # Initialize heuristics with zero
    heuristics = np.zeros_like(prize)
    
    # Normalize prize to reduce dominance by high values
    normalized_prize = prize / np.max(prize)
    
    # Define an initial exploration factor
    exploration_factor = np.random.rand(*normalized_prize.shape)
    
    # Combine exploration and exploitation
    exploitation_factor = normalized_prize * np.mean(weight, axis=1)
    
    # Add diversity by adding a random component
    diversity = np.random.normal(0, 0.02, size=normalized_prize.shape)
    diversity = np.maximum(diversity, 0)
    
    # Combine all factors
    combined_factor = exploration_factor + exploitation_factor + diversity
    
    # Amplify the heuristics based on a dynamic threshold
    amplification_threshold = np.percentile(combined_factor, 70)
    heuristics[combined_factor > amplification_threshold] = 1
    
    # Adapt thresholds dynamically
    dynamic_threshold = np.mean(combined_factor)
    heuristics[combined_factor > dynamic_threshold] *= 1.5
    
    # Encourage diversity by setting some heuristics to zero
    diversity_factor = np.random.rand(*normalized_prize.shape)
    diversity_factor = diversity_factor < np.percentile(diversity_factor, 30)
    heuristics[diversity_factor] = 0
    
    # Refine the heuristics by iterating and amplifying non-dominated items
    for _ in range(3):
        dominated_mask = np.zeros_like(combined_factor)
        dominated_mask[np.argsort(combined_factor, axis=0)[::-1]] = 1
        non_dominated_indices = np.where(np.logical_not(np.any(dominated_mask, axis=0, keepdims=True)))[0]
        heuristics[non_dominated_indices] *= 1.1
    
    # Normalize the heuristics to ensure they sum to 1
    heuristics /= np.sum(heuristics)
    
    return heuristics
```
