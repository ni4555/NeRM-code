```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n, m = prize.shape[0], weight.shape[1]

    # Normalize prize to the range [0, 1]
    normalized_prize = (prize - np.min(prize)) / (np.max(prize) - np.min(prize))

    # Calculate normalized density and sparsity
    density = normalized_prize / (np.sum(weight, axis=1) + 1e-8)
    sparsity = np.sum(weight, axis=1) / (np.max(weight, axis=1) + 1e-8)

    # Include a term for balance between high density and low sparsity
    balance_term = (density - sparsity) / (density + sparsity + 1e-8)

    # Include a term for the sum of weights, which can indicate a "bulkier" item
    weight_sum = np.sum(weight, axis=1)
    weight_sum_term = weight_sum / (np.max(weight_sum) + 1e-8)

    # Include a diversity factor based on the variance of density
    variance_density = np.var(density)
    diversity_factor = 1 / (variance_density + 1e-8)

    # Combine terms using a weighted sum
    combined_heuristic = 0.4 * balance_term + 0.3 * weight_sum_term + 0.3 * diversity_factor

    # Normalize the combined heuristic to ensure all values are within [0, 1]
    normalized_combined_heuristic = combined_heuristic / (np.max(combined_heuristic) + 1e-8)

    # Introduce an additional term that discourages inclusion of "dominant" items
    dominant_items = (np.sum(weight, axis=1) > np.mean(weight, axis=1))
    dominant_penalty = (dominant_items * (np.max(weight, axis=1) - np.mean(weight, axis=1))) / (np.max(weight, axis=1) + 1e-8)

    # Adjust combined heuristic based on the dominant penalty
    adjusted_heuristic = normalized_combined_heuristic * (1 - dominant_penalty)

    return adjusted_heuristic
```
