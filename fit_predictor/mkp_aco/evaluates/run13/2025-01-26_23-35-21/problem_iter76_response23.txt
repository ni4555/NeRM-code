```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n = prize.shape[0]
    m = weight.shape[1]

    # Calculate normalized density
    density = prize / np.sum(weight, axis=1) + 1e-8

    # Calculate normalized sparsity
    sparsity = np.sum(weight, axis=1) / np.sum(weight**2, axis=1) + 1e-8

    # Calculate the ratio of the square of prize to the sum of the squares of weight
    value_to_weight_ratio = (prize**2) / (np.sum(weight**2, axis=1) + 1e-8)

    # Prune dominated items early
    dominated_mask = density < np.percentile(density, 90)
    density[dominated_mask] = 0

    # Normalize value-to-weight ratio to focus on high ratios
    normalized_vwr = value_to_weight_ratio / np.max(value_to_weight_ratio)

    # Combine metrics using a weighted sum, balancing density, sparsity, and value-to-weight ratio
    combined_metrics = (0.5 * density +
                        0.3 * (1 - sparsity) +
                        0.2 * normalized_vwr)

    # Introduce randomness to encourage diversity
    random_factor = np.random.rand(n) + 1e-8

    # Adjust combined metrics with randomness
    adjusted_metrics = combined_metrics + random_factor

    # Normalize the adjusted metrics
    normalized_adjusted_metrics = adjusted_metrics / (np.max(adjusted_metrics) + 1e-8)

    # Encourage diversity by penalizing items that are too similar
    diversity_penalty = np.exp(-np.abs(normalized_adjusted_metrics - np.mean(normalized_adjusted_metrics)))
    final_heuristic = normalized_adjusted_metrics / diversity_penalty

    # Further refine the heuristic to give more weight to items with higher value-to-weight ratio
    final_heuristic *= normalized_vwr

    # Introduce a sparsity penalty for items with high sparsity, to encourage diversity
    sparsity_penalty = (1 - sparsity) * 0.1
    final_heuristic *= (1 - sparsity_penalty)

    return final_heuristic
```
