```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n, m = prize.shape[0], weight.shape[1]

    # Calculate normalized density for each item
    density = prize / (np.sum(weight, axis=1) + 1e-8)
    
    # Calculate normalized sparsity for each item
    sparsity = np.sum(weight, axis=1) / (np.max(weight, axis=1) + 1e-8)
    
    # Integrate additional metrics such as the sum of weights and average reward
    weight_sum = np.sum(weight, axis=1)
    average_reward = np.mean(prize)
    
    # Create a balanced heuristic value by blending metrics
    heuristic_value = density * (1 - sparsity) - weight_sum + (prize / average_reward)
    
    # Introduce a diversity factor based on the average density
    average_density = np.mean(density)
    diversity_factor = density / (average_density + 1e-8)
    
    # Create a final heuristic by combining the diversity factor with the heuristic value
    heuristic = heuristic_value * diversity_factor
    
    # Normalize by the maximum heuristic value
    normalized_heuristic = heuristic / (np.max(heuristic) + 1e-8)
    
    # Introduce an additional heuristic based on the balance between high density and low sparsity
    balance_heuristic = (density - sparsity) / (density + sparsity + 1e-8)
    
    # Use a weighted sum with exploration-exploitation balance
    exploration_balance = np.random.rand() * 0.3 + 0.7
    combined_heuristic = exploration_balance * normalized_heuristic + (1 - exploration_balance) * balance_heuristic
    
    # Set zero weights to a small value to maintain diversity
    combined_heuristic[weight_sum < 1e-8] = 1e-8
    
    # Introduce a random walk to encourage exploration
    random_walk = np.random.rand(n)
    combined_heuristic = combined_heuristic * (1 - random_walk) + random_walk
    
    return combined_heuristic
```
