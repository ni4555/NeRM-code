```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    n, m = prize.shape[0], weight.shape[1]

    # Normalize the prize to the sum of weights of each item
    normalized_prize = prize / np.sum(weight, axis=1) + 1e-8

    # Calculate the density of each item
    density = normalized_prize / (np.max(weight, axis=1) + 1e-8)

    # Calculate the sparsity of each item
    sparsity = np.sum(weight, axis=1) / np.max(weight, axis=1) + 1e-8

    # Calculate a balance metric between density and sparsity
    balance_metric = density - sparsity

    # Prune dominated solutions by removing those with a balance metric below the 95th percentile
    dominated_prune_threshold = np.percentile(balance_metric, 95)
    pruned_balance_metric = np.where(balance_metric >= dominated_prune_threshold, balance_metric, 0)

    # Introduce randomness to encourage diversity and avoid local optima
    random_factor = np.random.rand(n) * 0.1 + 0.05

    # Calculate diversity metrics based on how different each item is from the average density and sparsity
    average_density = np.mean(density)
    average_sparsity = np.mean(sparsity)
    diversity_density = (density - average_density) / (average_density + 1e-8)
    diversity_sparsity = (sparsity - average_sparsity) / (average_sparsity + 1e-8)
    diversity_metric = diversity_density + diversity_sparsity

    # Combine the heuristics using a weighted sum
    heuristics = (0.4 * pruned_balance_metric +
                  0.3 * density +
                  0.2 * diversity_metric +
                  0.1 * random_factor)

    # Normalize heuristics to ensure the sum is close to 1
    normalized_heuristics = heuristics / np.sum(heuristics)

    # Maintain diversity by setting low density items to zero
    min_density_threshold = np.percentile(density, 5)
    normalized_heuristics[np.where(density < min_density_threshold)] = 0

    return normalized_heuristics
```
