```python
import numpy as np

def heuristics_v2(prize: np.ndarray, weight: np.ndarray) -> np.ndarray:
    m = weight.shape[1]
    
    # Normalize weights and calculate the score for each item
    normalized_weights = np.linalg.norm(weight, axis=1) / np.sum(weight, axis=1)[:, None]
    score = np.sum(prize * normalized_weights, axis=1)
    
    # Calculate the weight ratio for each item
    ratio = prize / (np.sum(weight, axis=1) + 1e-8)  # Avoid division by zero
    
    # Calculate a combined importance metric using both score and ratio
    importance = score * ratio
    
    # Normalize the importance scores to ensure they can be compared across different items
    max_importance = np.max(importance)
    min_importance = np.min(importance)
    importance_normalized = (importance - min_importance) / (max_importance - min_importance)
    
    # Apply sparsity by setting a threshold and only including items above this threshold
    threshold = np.percentile(importance_normalized, 90)  # Use the 90th percentile as a threshold
    heuristics = (importance_normalized >= threshold).astype(float)
    
    # Adjust the heuristics scores to be more binary (0 or 1) while maintaining sparsity
    # Instead of using a fixed threshold, consider a balance between score and ratio
    combined_score_ratio = score / ratio
    max_combined_score_ratio = np.max(combined_score_ratio)
    min_combined_score_ratio = np.min(combined_score_ratio)
    combined_score_ratio_normalized = (combined_score_ratio - min_combined_score_ratio) / (max_combined_score_ratio - min_combined_score_ratio)
    
    # Apply a binary adjustment using a balanced threshold
    balanced_threshold = np.percentile(combined_score_ratio_normalized, 50)  # Use the median as a balanced threshold
    heuristics = (combined_score_ratio_normalized >= balanced_threshold).astype(float)
    
    return heuristics
```
