```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    n = distance_matrix.shape[0]
    edge_usage = np.zeros_like(distance_matrix)
    for i in range(n):
        for j in range(i+1, n):
            edge_usage[i, j] += 1
            edge_usage[j, i] += 1

    # Calculate the usage density, which is the ratio of the usage count to the number of possible edges
    usage_density = edge_usage / (n * (n - 1) / 2)

    # Introduce a non-linear transformation of usage density
    non_linear_usage = np.tanh(usage_density)

    # Calculate the average of non-linear usage density
    average_non_linear_usage = np.mean(non_linear_usage)

    # Balance adjustments for non-linear usage
    adjusted_distances = distance_matrix * (1 + 0.1 * (non_linear_usage > average_non_linear_usage))

    # Introduce noise based on edge properties
    noise = np.random.normal(size=(n, n)) * np.sqrt(np.mean(adjusted_distances))
    adjusted_distances += noise

    # Refine penalties based on edge length and density
    length_penalty = (distance_matrix > adjusted_distances.mean())
    adjusted_distances[length_penalty] += adjusted_distances[length_penalty].max() * 0.1

    # Normalize data to ensure feasibility
    min_distance = 0.01
    max_distance = adjusted_distances.max()
    adjusted_distances = (min_distance + adjusted_distances) / (min_distance + max_distance)

    # Control variance using the maximum value from the original distance matrix
    max_possible = distance_matrix.max()
    adjusted_distances = adjusted_distances * max_possible

    return adjusted_distances
```
