```python
def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    num_nodes = distance_matrix.shape[0]
    heuristics = np.zeros_like(distance_matrix)

    # Introduce a balance between direct and loop penalties
    direct_penalty = 1
    loop_penalty = 10

    for i in range(num_nodes):
        for j in range(num_nodes):
            if i != j:
                # Calculate the sum of distances for the current edge and the previous and next edges in a loop
                loop_distance = distance_matrix[i, j] + distance_matrix[j, np.roll(i, 1)] + distance_matrix[np.roll(i, 1), j]
                direct_distance = distance_matrix[i, np.roll(i, 1)]
                
                # Balance the penalties based on the relative distances
                penalty = direct_penalty * direct_distance + loop_penalty * (loop_distance - direct_distance)

                # Foster diversity by penalizing edges that are part of a frequently visited path
                frequency_penalty = np.sum(distance_matrix, axis=0)[i] * np.sum(distance_matrix, axis=1)[j]
                penalty += frequency_penalty

                heuristics[i, j] = penalty

    # Apply a global penalty for large distances to encourage exploration
    large_distance_penalty = 1e6
    heuristics[distance_matrix > large_distance_penalty] = large_distance_penalty - distance_matrix[distance_matrix > large_distance_penalty]

    return heuristics
```
