```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    n = distance_matrix.shape[0]
    edge_usage = np.zeros_like(distance_matrix)
    
    # Calculate the usage of each edge
    for i in range(n):
        for j in range(i+1, n):
            edge_usage[i, j] = edge_usage[j, i] = 1
    
    # Calculate the cumulative distribution of edge usage
    sorted_usage = np.sort(edge_usage, axis=1)
    for i in range(n):
        sorted_usage[i] = np.cumsum(sorted_usage[i])
    
    # Calculate a more nuanced usage threshold based on the 25th percentile
    usage_threshold = sorted_usage[:, int(n * 0.25)]
    
    # Adjust distances based on usage and position in the cumulative distribution
    adjusted_distances = distance_matrix * (1 + 0.1 * (edge_usage > usage_threshold))
    
    # Introduce variability with a Gaussian perturbation to avoid local minima
    perturbation = np.random.normal(0, 0.01, (n, n))
    
    # Scale the perturbation based on the distance matrix to maintain feasibility
    perturbation /= np.linalg.norm(distance_matrix, axis=1, keepdims=True)
    perturbation /= np.linalg.norm(perturbation, axis=1, keepdims=True)
    
    # Introduce a balance factor to control the influence of the perturbation
    balance_factor = np.random.rand(n, n)
    balance_factor = balance_factor / np.max(balance_factor)
    
    # Apply the perturbation to the adjusted distances with the balance factor
    adjusted_distances += perturbation * balance_factor
    
    # Ensure that the adjusted distances are not negative
    adjusted_distances = np.maximum(adjusted_distances, 0)
    
    # Introduce a dampening factor to control the extent of distance adjustments
    dampening_factor = np.exp(-0.5 * np.abs(sorted_usage - usage_threshold))
    dampening_factor /= np.max(dampening_factor)
    
    # Apply the dampening factor to the adjusted distances
    adjusted_distances *= dampening_factor
    
    return adjusted_distances
```
