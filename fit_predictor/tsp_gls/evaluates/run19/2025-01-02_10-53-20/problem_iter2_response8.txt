```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    # Introduce a penalty for high degree vertices and a reward for short paths
    degree_penalty = np.sum(distance_matrix, axis=0) ** 2
    short_path_reward = np.log(distance_matrix + 1)

    # Adjust the penalties and rewards to ensure they do not overshadow each other
    adjusted_degree_penalty = degree_penalty * 0.5
    adjusted_short_path_reward = short_path_reward * 1.5

    # Calculate a balance factor to prevent one type of adjustment from dominating the other
    balance_factor = np.sum(adjusted_degree_penalty) / np.sum(adjusted_short_path_reward)

    # Combine both penalties and rewards with the balance factor to get the heuristic values
    heuristic_values = adjusted_degree_penalty - adjusted_short_path_reward * balance_factor

    # Ensure that the heuristic values are not too high or too low to allow for exploration
    # and to encourage the use of a diverse set of edges
    min_val = np.min(heuristic_values)
    max_val = np.max(heuristic_values)
    heuristic_values = (heuristic_values - min_val) / (max_val - min_val) * 100

    return heuristic_values
```
